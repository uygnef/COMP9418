{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Document Classification\n",
    "\n",
    "**COMP9418-17s2, W01 Tutorial**\n",
    "\n",
    "- Instructor: Edwin V. Bonilla\n",
    "- School of Computer Science and Engineering, UNSW Sydney \n",
    "- Questions by Daniel Mackinlay (with input and edits from Edwin V. Bonilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will further explore\n",
    "the basis of the Na√Øve Bayes Classifier.\n",
    "We will use, specifically, the Bernoulli-Dirichlet model for text classification,\n",
    "We will train the model using both the Maximum Likelihood estimates and Bayesian updating,\n",
    "and compare these in terms of predictive success, and in terms of what can go wrong.\n",
    "\n",
    "We will be using the `webkb` dataset.\n",
    "This data set contains web pages collected from computer science departments\n",
    "of various universities in January 1997\n",
    "by the _World Wide Knowledge Base_ project of the _CMU text learning group_.\n",
    "\n",
    "The pages have been manually classified into categories;\n",
    "our goal is to classify documents into those categories using the content of the page.\n",
    "\n",
    "The original data is full HTML files.\n",
    "If you would like to see the original data, or learn more about it,\n",
    "see [the webkb dataset website](http://www.cs.cmu.edu/afs/cs/project/theo-20/www/data/).\n",
    "\n",
    "We have preprocessed a subset of that data into numerical arrays,\n",
    "to which we can apply the classifier directly.\n",
    "(But if you are interested in learning to process the text yourself, feel free to use the original data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run these commands:\n",
    "\n",
    "```python\n",
    "pip install scipy matplotlib\n",
    "```\n",
    "\n",
    "You will also need to download the preprocessed `webkb` data set\n",
    "(see file `webkb.npz` in WebCMS3)\n",
    "and put it in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done all that, we\n",
    "import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "\n",
    "# Necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline\n",
    "\n",
    "# Display a warning on important floating-point errors\n",
    "np.seterr(divide='warn', invalid='warn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "These data are in `npz` compressed `numpy` format, which can be loaded using `np.load`.\n",
    "Make sure you have downloaded the data first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\n",
    "    'webkb.npz',\n",
    ")\n",
    "\n",
    "# training data\n",
    "xtrain = data['xtrain']\n",
    "ytrain = data['ytrain']\n",
    "\n",
    "# test data\n",
    "xtest = data['xtest']\n",
    "ytest = data['ytest']\n",
    "\n",
    "# which class is which?\n",
    "class_label_strings = data['class_label_strings']\n",
    "\n",
    "# we don't need the original any more\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, here is a useful function for plotting bar charts from this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_bar(val, **kwargs):\n",
    "    \"\"\"\n",
    "    Convenient categorical bar plot, labelled with the class strings.\n",
    "    This is handy if you want to plot something versus class.\n",
    "    \"\"\"\n",
    "    n_cat = len(class_label_strings)\n",
    "    cat_index = np.arange(n_cat)\n",
    "    bar = pl.bar(cat_index, val, width=1, **kwargs);\n",
    "    pl.xticks(cat_index, class_label_strings)\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $X$ arrays above are the *features*.\n",
    "Each array is an $N \\times D$ matrix,\n",
    "whose rows correspond to the number of training points-\n",
    "so $N$ is the number of data points,\n",
    "and $D$ is the number of features.\n",
    "\n",
    "The $Y$ arrays, $Y^\\text{train}$ and $Y^\\text{test}$ are $N \\times C$ column vectors,\n",
    "each row containing the one-hot encoded class label of the corresponding training point.\n",
    "\n",
    "The data sets are divided into *training* and *test* sets;\n",
    "We will not be using the test data except to test predictions later in the tutorial.\n",
    "\n",
    "Each data point represents one text _document_ -\n",
    "in this data set, one document equals one web page.\n",
    "The features here are indicators of the presence, or absence, of a word in a given page.\n",
    "So if $X_{ij}=1$, we know that document $i$ contains word $j$.\n",
    "In this data set, however, we do not know which feature corresponds to which word.\n",
    "This is a special case of the _bag of words_ method, and it will allow us to model\n",
    "the document features using Bernoulli random variables.\n",
    "\n",
    "\n",
    "Given that description, we check the data has the size we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training data dimensions = (702, 1703)\n",
      "Y training data dimensions = (702, 5)\n",
      "X test data dimensions     = (175, 1703)\n",
      "Y test data dimensions     = (175, 5)\n",
      "Number of y labels         = 5\n"
     ]
    }
   ],
   "source": [
    "print(\"X training data dimensions = {!r}\".format(xtrain.shape))\n",
    "print(\"Y training data dimensions = {!r}\".format(ytrain.shape))\n",
    "print(\"X test data dimensions     = {!r}\".format(xtest.shape))\n",
    "print(\"Y test data dimensions     = {!r}\".format(ytest.shape))\n",
    "print(\"Number of y labels         = {!r}\".format(len(class_label_strings)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the content of the arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot frequencies of all the features/words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d40f91b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.bar(np.arange(xtrain.shape[1]), np.sum(xtrain, axis=0), width=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the class-conditional features density for two different classes -\n",
    "that is, given, say, class $2$ and class $3$, plot what proportion the examples in each class have which features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "incompatible sizes: argument 'height' must be length 1703 or scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e41d0909d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(left, height, width, bottom, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m         ret = ax.bar(left, height, width=width, bottom=bottom, data=data,\n\u001b[0;32m-> 2705\u001b[0;31m                      **kwargs)\n\u001b[0m\u001b[1;32m   2706\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1890\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1891\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, left, height, width, bottom, **kwargs)\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnbars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             raise ValueError(\"incompatible sizes: argument 'height' \"\n\u001b[0;32m-> 2079\u001b[0;31m                               \"must be length %d or scalar\" % nbars)\n\u001b[0m\u001b[1;32m   2080\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnbars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m             raise ValueError(\"incompatible sizes: argument 'width' \"\n",
      "\u001b[0;31mValueError\u001b[0m: incompatible sizes: argument 'height' must be length 1703 or scalar"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d42b897b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2 = xtrain[ytrain[:, 2] == 1, :]\n",
    "x3 = xtrain[ytrain[:, 3] == 1, :]\n",
    "\n",
    "pl.bar(np.arange(x2.shape[1]), np.mean(x2), width=1);\n",
    "pl.bar(np.arange(x3.shape[1]), np.mean(x3), width=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So much for the $X$ arrays. How about the $Y$ arrays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the number of training documents in each class in the training data.\n",
    "Identify the smallest and largest classes.\n",
    "Are they evenly distributed? What effect will this have on our results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Maximum Likelihood Na√Øve Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to the MLE fitting, the classifier is specified by the following parameters\n",
    "\n",
    "- $\\boldsymbol{\\pi}$, where $\\pi_c=p(y=c)$ the marginal probability that a document is in category $c$\n",
    "- $\\boldsymbol{\\theta}$, where $\\theta_{jc}=p(x_{j}=1|y_c=1),$ the class-conditional probability of each feature.\n",
    "\n",
    "\n",
    "We construct ML point estimates of the vector parameters\n",
    "$\\hat{\\boldsymbol{\\pi}}$ \n",
    "and \n",
    "$\\hat{\\boldsymbol{\\theta}}$.\n",
    "\n",
    "The MLE estimates may be calculated as follows (Using the notation of Murphy, 3.5)\n",
    "\n",
    "For the class probabilities,\n",
    "$$\n",
    "\\hat{\\pi}_c=\\frac{N_c}{N},\n",
    "$$\n",
    "where $N_c$ is the number of examples in class $c$.\n",
    "\n",
    "For the conditional feature probabilities,\n",
    "$$\\hat{\\theta}_{jc}=\\frac{N_{jc}}{N_c},$$\n",
    "where $N_{jc}$ is the number of occurrences of feature $j$ in class $c$.\n",
    "\n",
    "Here is a function to calculate this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_naive_bayes_ml(x, y):\n",
    "    \"\"\"\n",
    "    Given an array of features `x` and an array of labels `y`,\n",
    "    return ML estimates of class probabilities `pi` and\n",
    "    class-conditional feature probabilities `theta`.\n",
    "    \"\"\"\n",
    "    n_class = y.shape[1]\n",
    "    n_feat = x.shape[1]\n",
    "    \n",
    "    pi_counts = np.sum(y, axis=0)\n",
    "    pi = pi_counts/np.sum(pi_counts)\n",
    "    \n",
    "    theta = np.zeros((n_feat, n_class))\n",
    "\n",
    "    for cls in range(n_class):\n",
    "        docs_in_class = (y[:, cls]==1)\n",
    "        class_feat_count = x[docs_in_class, :].sum(axis=0)\n",
    "        theta[:, cls] = class_feat_count/(docs_in_class.sum())\n",
    "    return pi, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi_hat, theta_hat = fit_naive_bayes_ml(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Plot the class probabilites obtained by the ML estimator using the `categorical_bar` function.\n",
    "How different is it from the proportion of classes in each category that we plotted earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the class probability predictor, given our parameter estimates.\n",
    "This will involve two functions.\n",
    "One function, `predict_class_prob`, will give the posterior class likelihood for a given document.\n",
    "The second function, `predict_class`,\n",
    "will choose the highest-probability class as a MAP-prediction for a given document.\n",
    "\n",
    "These function are provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "\n",
    "def predict_class_prob(x, pi, theta):\n",
    "    \"\"\"\n",
    "    Given an single array of features `x`,\n",
    "    class probability estimate `pi` and\n",
    "    class-conditional feature probability estimate `theta`,\n",
    "    return predictive class probabilities.\n",
    "    \"\"\"\n",
    "    class_feat_l = np.zeros_like(theta)\n",
    "    \n",
    "    # calculations in log space to avoid underflow\n",
    "    class_feat_l[x==1, :] = np.log(theta[x==1, :])\n",
    "    class_feat_l[x==0, :] = np.log(1 - theta[x==0, :])\n",
    "    class_l = class_feat_l.sum(axis=0) + np.log(pi)\n",
    "    return np.exp(class_l - logsumexp(class_l))\n",
    "\n",
    "\n",
    "def predict_class(x, pi, theta):\n",
    "    \"\"\"\n",
    "    Given a feature vector `x`, class probabilities `pi`\n",
    "    and class-conditional feature probabilities `theta`,\n",
    "    return a one-hot encoded MAP class-membership prediction.\n",
    "    \"\"\"\n",
    "    probs = predict_class_prob(x, pi, theta)\n",
    "    prediction = np.zeros_like(probs)\n",
    "    prediction[np.argmax(probs)] = 1\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implement these predictors using likelihoods without the **log-sum-exp** trick, what happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the some predicted probabilities under this model.\n",
    "\n",
    "Consider the first example from the test set, $X^\\text{test}_{0,:}$.\n",
    "Its true class membership (one-hot encoded) is  $Y^\\text{test}_{0,:}$.\n",
    "We can plot this and see that this document is a \"Student\" web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoMMd0lq0P8D+4UI6hYr7osAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d910d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_bar(ytest[0,:], label=\"$y$\", color='blue');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Plot the predicted class probabilities for the first training example\n",
    "$X^\\text{test}_{0,:}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may of course repeat this exercise for other examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can in principle infer class probabilities for any given example.\n",
    "But since we have a lot of these,\n",
    "we will define a helper function to quantify how good our predictions are over a whole data set.\n",
    "\n",
    "We assign a score of $1$ for a correct MAP prediction, or $0$ for an incorrect prediction.\n",
    "The mean of these is a measure of the quality of our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictive_accuracy(xdata, ydata, predictor, *args):\n",
    "    \"\"\"\n",
    "    Given an N-by-D array of features `xdata`,\n",
    "    an N-by-C array of one-hot-encoded true classes `ydata`\n",
    "    and a predictor function `predictor`,\n",
    "    return the proportion of correct predictions.\n",
    "    \n",
    "    We accept an additional argument list `args`\n",
    "    that will be passed to the predictor function.\n",
    "    \"\"\"\n",
    "    correct = np.zeros(xdata.shape[0])\n",
    "    for i, x in enumerate(xdata):\n",
    "        prediction = predictor(x, *args)\n",
    "        correct[i] = np.all(ydata[i, :] == prediction)\n",
    "    return correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did we do?\n",
    "We examine our performance on the held-out test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Out-of-sample proportion correct: 0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:16: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "test_correct_ml = predictive_accuracy(xtest, ytest, predict_class, pi_hat, theta_hat)\n",
    "print(\"ML Out-of-sample proportion correct: {:.3}\".format(test_correct_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Calculate this accuracy metric on the training data.\n",
    "What does it tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis: What are these warnings about?\n",
    "\n",
    "These results lead to two questions:\n",
    "\n",
    "1. Is the accuracy  any good?\n",
    "2. Do all these  `RuntimeWarning: divide by zero` messages mean anything?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Look at test document number 48.\n",
    "Plot the predicted class probabilites.\n",
    "What is wrong in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Have we over- or under-estimated our predictor's test-set success on the basis of this diagnosis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Alter the function `predict_class` belo to detect\n",
    "this failure mode, and to return a ‚Äúlikelihood‚Äù of $(0 0 0 0 0)$ in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class(x, pi, theta):\n",
    "    \"\"\"\n",
    "    Given a feature vector `x`, class probabilities `pi`\n",
    "    and class-conditional feature probabilities `theta`,\n",
    "    Return a one-hot encoded class-membership prediction.\n",
    "    If the class probabilities are ill-defined, return a null prediction.\n",
    "    \"\"\"\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this doesn't fix the prediction - but it gives us a more realistic perspective on the performance of the estimator.\n",
    "(What other solutions might be better?)\n",
    "\n",
    "**Pro tip**: to keep things tidy now in the notebook, we can disable these `Warning` messages.\n",
    "```\n",
    "np.seterr(divide='ignore', invalid='ignore');\n",
    "```\n",
    "In general, you should _not_ do this unless you have very good reason to think that the warnings are unimportant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-test the model without spurious predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Na√Øve Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with, as in the class, a Dirichlet prior for the classes, and an identical Beta prior for each class-conditional feature probability:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\boldsymbol{\\pi}&\\sim\\operatorname{Dir}(\\boldsymbol{\\alpha})\\\\\n",
    "\\theta_{jc}&\\sim\\operatorname{Beta}(\\boldsymbol{\\beta}) \\text{ for each }j, c\n",
    "\\end{aligned}$$\n",
    "\n",
    "Note that the parameters of the prior distributions are both vectors,\n",
    "$\\boldsymbol{\\alpha}=(\\alpha_1, \\alpha_2, \\dots, \\alpha_C)$ and $\\boldsymbol{\\beta}=(\\beta_0, \\beta_1).$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fully Bayesian setting, we would calculate full posteriors for all model parameters.\n",
    "However, in this predictive task, we only use posterior means $\\bar{\\boldsymbol{\\theta}}$\n",
    "and $\\bar{\\boldsymbol{\\pi}}$,\n",
    "so it will be sufficient (and a little bit simpler) to calculate just these.\n",
    "\n",
    "Recall\n",
    "$$\n",
    "\\bar{\\pi}_c=\\frac{N_c+\\alpha_c}{N+\\alpha_0},\n",
    "$$\n",
    "where $\\alpha_0$ means $\\sum_c \\alpha_c.$\n",
    "\n",
    "For the conditional feature probabilities,\n",
    "$$\n",
    "\\bar{\\theta}_{jc}=\\frac{N_{jc}+\\beta_1}{N_c+\\beta_0+\\beta_1}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Below is the skeleton of the function `naive_bayes_posterior_mean`.\n",
    "Fill in the body of this function so that it calculates the desired posterior means.\n",
    "You are recommended to copy `fit_naive_bayes_ml`, above, and modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_posterior_mean(x, y, alpha=1, beta=1):\n",
    "    \"\"\"\n",
    "    Given an array of features `x`,\n",
    "    an array of labels `y`,\n",
    "    class prior Dirichlet parameter `alpha`, and\n",
    "    common class-conditional feature expectation `beta`\n",
    "    return \n",
    "    \n",
    "    a posterior mean, `pi`, of `alpha` and\n",
    "    a posterior mean, `theta` of the `beta`.\n",
    "    \n",
    "    NB: this is not the same as returning the parameters of the full posterior,\n",
    "    but it is sufficient to calculate the posterior predictive density.\n",
    "    \"\"\"\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate these values.\n",
    "We need to choose our priors.\n",
    "Since we know we would like *some* smoothing in comparison to the ML estimator,\n",
    "we should not not choose uninformative priors.\n",
    "One possible starting point would be $\\boldsymbol{\\alpha}=(1,1,\\dots,1),\\, \\boldsymbol{\\beta}=(1,1).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the posterior mean, $\\bar{\\boldsymbol{\\pi}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Plot the new class likelihoods on the troublesome test document $48$?\n",
    "Plot the true classification for the document also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we do over the whole data set? Compute accuracy on test data and on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of posterior class density between ML and Bayes methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the posterior class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There will be no visible difference between these!\n",
    "categorical_bar(pi_bar, color='green', alpha=0.5, label=r'$\\bar{\\pi}$');\n",
    "categorical_bar(pi_hat, color='magenta', alpha=0.5, label=r'$\\hat{\\pi}$');\n",
    "pl.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the posterior mean $\\bar{\\boldsymbol{\\pi}}$ is very similar using this weakly informative prior, we can observe different densities using different priors.\n",
    "\n",
    "Plot the inferred $\\bar{\\boldsymbol{\\pi}}$ if we start with a prior $\\boldsymbol{\\alpha}=(100,100,\\dots,100).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Performance with Test Likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of having probabilistic models is that we actually have probabilities (or uncertainties) on our predictions. Here we will compute the log likelihood of our test data given our models as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L}_\\text{test}  =  \\frac{1} {N_\\text{test}}\\sum_{i=1}^{N_\\text{test}} \\log p(y^{(i)}_\\text{test} | \\mathbf{x}^{(i)}_\\text{test}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with log-likelihoods instead of plain likelihoods unless otherwise stated, since the probabilities involved can be very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `test_likelihood` that receives features, true labels and a probabilistic predictor and return the test (log) likelihood as defined above. HINT: You should write a function similar to `predictive_accuracy` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_likelihood(xdata, ydata, predictor, *args):\n",
    "    \"\"\"\n",
    "    Given an N-by-D array of features `xdata`,\n",
    "    an N-by-C array of one-hot-encoded true classes `ydata`\n",
    "    and a predictor function `predictor` of probabilities,\n",
    "    return the log likelihood of the test data under that model.\n",
    "    \n",
    "    We accept an additional argument list `args`\n",
    "    that will be passed to the predictor function.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the test likelihoods for the Maximum Likelihood and the Bayesian models, and compare their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
