{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 (Part 2)\n",
    "** COMP9418 - Advanced Topics in Statistical Machine Learning **\n",
    "\n",
    "** Instructor: Edwin V. Bonilla **\n",
    "\n",
    "** Last update: August 23rd at 10:35pm **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "In this practical part of the assignment you will build a class-conditional classifer using Gaussian Mixture Models (GMMs). \n",
    "\n",
    "1. For all the machine-learning related code you have two options: (a) use [scikit-learn](http://scikit-learn.org/stable/) and/or (b) write your own code. In particular, for fitting GMMs or building the classifier, you should refrain from using other packages. \n",
    "2. You can use the same GMM package that we used in the corresponding tutorial on GMMs, i.e. [scikit-learn Gaussian Mixture](http://scikit-learn.org/stable/modules/mixture.html). You should use standard (non-variational) Expectation-Maximisation updates  for parameter estimation. \n",
    "3. Do not delete any of the existing code in this notebook as we will use it to assess the performance of your algorithm.\n",
    "\n",
    "### Main task\n",
    "Your tasks is to build a class-conditional classifier for classifying digits using the MNIST dataset. You are given a file `mnist_train.npz` that contains images of digits (0-9). \n",
    "- The features `xtrain`, which have been normalized to be between [0,1], are 784 dimensional vectors corresponding to 28 * 28 image intensities. \n",
    "- The targets `ytrain` contain the class label of each example using one-hot-encoding. \n",
    "- In total there are 60,000 examples, each with one label from the 10 different classes. \n",
    "- The original dataset can be found at http://yann.lecun.com/exdb/mnist/ and you can read more about this dataset there. However, this dataset has been processed and shuffled so the training and test data in this exercise do not correspond to the original sets. \n",
    "- Note that you are only provided with training data `xtrain`, `ytrain`. In order to learn and test you model, you may consider splitting these data into training, validation and testing.   In particular, if you want to assess the performance of your model in section 2, you must create a test set `mnist_test.npz`. You are not required to submit this test file as we will evaluate the performance of your model using our own test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher\n",
    "Recall that a class-conditional classifier models the joint distribution of features $\\mathbf{x}$ and classes $y$ as $p(\\mathbf{x}, y) = p(y) p(\\mathbf{x} | y)$ and then uses Bayes' rule $p(y | \\mathbf{x}) \\propto  p(y) p(\\mathbf{x} | y)$ to make predictions. In this assignment, you will use a GMM for each of the conditional densities $p(\\mathbf{x} | y)$ and a Categorical distribution for $p(y)$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment\n",
    "Your work will be assessed based on:\n",
    "- [50%] the application of the concepts for doing model selection, which allows you to learn a single model for prediction (Section 1);  \n",
    "- [30%] the code you write for making predicitions in your model (Section 2); and\n",
    "- [20%] the predictive performance of your model (Section 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages \n",
    "Add required libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sklearn as skl\n",
    "\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function below to plot a digit in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(array, dim=28):\n",
    "    \"\"\"\n",
    "    Plot array as an image of dimensions dim * dim\n",
    "    \"\"\"\n",
    "    img = array.reshape(dim,dim, order = \"C\")\n",
    "    pl.imshow(img, cmap=pl.cm.gray)\n",
    "    ax = pl.gca();ax.set_yticks([]);ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you should load your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000L, 784L)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('mnist_train.npz')\n",
    "\n",
    "# training data\n",
    "xtrain = data['xtrain']\n",
    "ytrain = data['ytrain']\n",
    "xtest = xtrain[50000:]\n",
    "ytest = ytrain[50000:]\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here and example of plotting a specific digit and showing its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwIJFwIJFwL9F1rvFqkWhbDJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16fa0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "plot_image(xtrain[idx,:])\n",
    "print(ytrain[idx,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [50%] Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place all the code for training your model using the function `train_model` below. \n",
    "\n",
    "- We should be able to run your notebook (by clicking 'Cell->Run All') without errors. However, you must save the trained model in the file `model.npz`. This file will be loaded to make predictions in section 2 and assess the performance of your model in section 3. Note that, in addition to this notebook file, <span style=\"color:red\"> ** you must provide the file model.npz **</span>.\n",
    "\n",
    "- You should comment your code as much as possible so we understand your reasoning about training, model selection and avoiding overfitting. \n",
    "\n",
    "- You can process the data as you wish, e.g. by applying some additonal transformations, reducing dimensionality, etc. However, all these should be here too. \n",
    "- Wrap all your training using the function `train_model` below. You can call all other custom functions within it.\n",
    "\n",
    "- I strongly discourage you from using a full covariance for each of the components of your Gaussian mixture, as the number of parameters grows quadratically on the dimensionality of the data and you will be unable to fit the file size cap in your submission (besides running into various numerical issues). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xtrain, ytrain):\n",
    "    \"\"\"\n",
    "    Write your code here.\n",
    "    \"\"\"\n",
    "    import sklearn.mixture\n",
    "    import sklearn.decomposition\n",
    "\n",
    "    #use PCA to preprocess data\n",
    "    reducer = sklearn.decomposition.PCA(n_components=40)\n",
    "    reducer.fit(xtrain)\n",
    "    xtrain = reducer.transform(xtrain)\n",
    "    \n",
    "    model = []\n",
    "    for i in range(10):\n",
    "        sub_model = sklearn.mixture.GaussianMixture(n_components=9)\n",
    "        sub_model.fit(xtrain[ytrain[:, i] == 1])\n",
    "        model.append(sub_model)\n",
    "\n",
    "    model.append(reducer)\n",
    "    # You can modify this to save other variables, etc\n",
    "    # but make sure the name of the file is 'model.npz.\n",
    "    np.savez_compressed(\n",
    "        'model.npz',\n",
    "        model=model,\n",
    "    )\n",
    "train_model(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [30%] Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will assume that there is a file `mnist_test.npz` from which we will load the test data.  As this file is not given to you, you will need to create one yourself (but not to submit it) to test your code. <span style=\"color:red\">Note that if you do not create this file the cell below will not run</span>. \n",
    "\n",
    "Your task is to fill in the `make_predictions` function below. Note that this function should load your `model.npz` file, which must contain all the data structures necessary for making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuBBIuBBIuBBIuBBIuBBIuBBIuBDoH6pnCIrcnfVtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16fc7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1000\n",
    "plot_image(xtest[idx,:])\n",
    "print (ytest[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(xtest):\n",
    "    \"\"\"\n",
    "    @param xtest: (Ntest,D)-array with test data\n",
    "    @return class_pred: (N,C)-array with predicted classes using one-hot-encoding\n",
    "    @return class_logprob: (N,C)-array with  predicted log probability of the classes\n",
    "    \"\"\"\n",
    "\n",
    "    # Add your code here: You should load your trained model here\n",
    "    # and write to the corresponding code for making predictions\n",
    "\n",
    "    #load model\n",
    "    model = np.load('model.npz');\n",
    "    gmm_and_pca = model['model'].tolist();\n",
    "    #use PCA\n",
    "    render = gmm_and_pca[-1]\n",
    "    model_list = gmm_and_pca[:-1]\n",
    "    xtest = render.transform(xtest)\n",
    "\n",
    "    class_logprob = []\n",
    "    # calculate all probablities for 10 digit model\n",
    "    for i, gmm in enumerate(model_list):\n",
    "        class_logprob.append(np.ma.log(gmm.score_samples(xtest)))\n",
    "\n",
    "    # select the largest probablity for each test data as predict value\n",
    "    class_logprob = np.array(class_logprob).T\n",
    "    class_pred = np.zeros_like(class_logprob)\n",
    "    class_pred[np.arange(len(class_logprob)), class_logprob.argmax(1)] = 1\n",
    "    return class_pred, class_logprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e51f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(xtest[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [20%] Performance \n",
    "You do not need to do anything in this section but you can use it to test the generalisation performance of your code. We will use it the evaluate the performance of your algorithm on a new test test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictive_performance(xdata, ydata, class_pred, class_logprob):\n",
    "    \"\"\"\n",
    "    @param xdata:  (N,D)-array of features \n",
    "    @param ydata:  (N,C)-array of one-hot-encoded true classes\n",
    "    @class_pred: (N,C)-array of one-hot-encoded predicted classes\n",
    "    @class_logprob: (N,C)-array of predicted class log probabilities \n",
    "    \"\"\"\n",
    "    correct = np.zeros(xdata.shape[0])\n",
    "    ltest = np.zeros(xdata.shape[0])\n",
    "    for i, x in enumerate(xdata):\n",
    "        correct[i] = np.all(ydata[i, :] == class_pred[i,:])\n",
    "        ltest[i] = class_logprob[i, np.argmax(ydata[i,:])]\n",
    "    accuracy = correct.mean()\n",
    "    loglike = ltest.mean()\n",
    "    return accuracy, loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred, class_logprob = make_predictions(xtest)\n",
    "accuracy, loglike = predictive_performance(xtest, ytest, class_pred, class_logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy=0.9868\n",
      "Average test likelihood=-19.0841600324\n"
     ]
    }
   ],
   "source": [
    "print ('Average test accuracy=' + str(accuracy))\n",
    "print ('Average test likelihood=' + str(loglike))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw data:\n",
    "\n",
    "n_componets:\n",
    "1 componts: used  21.498249292373657  s\n",
    "Average test accuracy=0.8017\n",
    "Average test likelihood=-1149.14087779\n",
    "\n",
    "2 componts: used  116.86499738693237  s\n",
    "Average test accuracy=0.8384\n",
    "Average test likelihood=-1981.87574627\n",
    "\n",
    "3 componts: used  180.3983657360077  s\n",
    "Average test accuracy=0.8299\n",
    "Average test likelihood=-2158.97579671\n",
    "\n",
    "4 componts: used  358.132700920105  s\n",
    "Average test accuracy=0.8453\n",
    "Average test likelihood=-2873.26131067\n",
    "\n",
    "5 componts: used  383.3107109069824  s\n",
    "Average test accuracy=0.8476\n",
    "Average test likelihood=-3419.58633082\n",
    "\n",
    "6 componts: used  524.2214524745941  s\n",
    "Average test accuracy=0.8476\n",
    "Average test likelihood=-3957.56467117\n",
    "\n",
    "7 componts: used  425.6201946735382  s\n",
    "Average test accuracy=0.8367\n",
    "Average test likelihood=-5244.58334364\n",
    "\n",
    "8 componts: used  476.47383093833923  s\n",
    "Average test accuracy=0.8333\n",
    "Average test likelihood=-6441.75292405\n",
    "\n",
    "9 componts: used  523.8272912502289  s\n",
    "Average test accuracy=0.832\n",
    "Average test likelihood=-8606.70204971\n",
    "\n",
    "10 componts: used  431.04791355133057  s\n",
    "Average test accuracy=0.8227\n",
    "Average test likelihood=-12179.4023153\n",
    "\n",
    "11 componts: used  355.5475335121155  s\n",
    "Average test accuracy=0.8166\n",
    "Average test likelihood=-17528.0840164\n",
    "\n",
    "12 componts: used  480.70417070388794  s\n",
    "Average test accuracy=0.8064\n",
    "Average test likelihood=-25019.7198517\n",
    "\n",
    "13 componts: used  385.29809069633484  s\n",
    "Average test accuracy=0.7751\n",
    "Average test likelihood=-32734.7037463\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PCA only\n",
    "1 componts: used  3.081974744796753  s\n",
    "Average test accuracy=0.9597\n",
    "Average test likelihood=-32.3879492786\n",
    "\n",
    "2 componts: used  6.273758888244629  s\n",
    "Average test accuracy=0.9612\n",
    "Average test likelihood=-27.6208604877\n",
    "\n",
    "3 componts: used  8.713711023330688  s\n",
    "Average test accuracy=0.9664\n",
    "Average test likelihood=-25.1722310301\n",
    "\n",
    "4 componts: used  11.252529382705688  s\n",
    "Average test accuracy=0.9687\n",
    "Average test likelihood=-23.8816807071\n",
    "\n",
    "5 componts: used  13.068610429763794  s\n",
    "Average test accuracy=0.9721\n",
    "Average test likelihood=-23.0051538614\n",
    "\n",
    "6 componts: used  14.917632102966309  s\n",
    "Average test accuracy=0.9724\n",
    "Average test likelihood=-22.3775335339\n",
    "\n",
    "7 componts: used  20.368378400802612  s\n",
    "Average test accuracy=0.9752\n",
    "Average test likelihood=-21.7035714913\n",
    "\n",
    "8 componts: used  24.292773723602295  s\n",
    "Average test accuracy=0.9745\n",
    "Average test likelihood=-21.3464549563\n",
    "\n",
    "9 componts: used  25.20234704017639  s\n",
    "Average test accuracy=0.9776\n",
    "Average test likelihood=-20.98708924\n",
    "\n",
    "10 componts: used  32.83976984024048  s\n",
    "Average test accuracy=0.975\n",
    "Average test likelihood=-20.7707614943\n",
    "\n",
    "11 componts: used  29.55973505973816  s\n",
    "Average test accuracy=0.9766\n",
    "Average test likelihood=-20.7849548249\n",
    "\n",
    "12 componts: used  35.253512382507324  s\n",
    "Average test accuracy=0.9751\n",
    "Average test likelihood=-20.4957955782\n",
    "\n",
    "13 componts: used  35.635204792022705  s\n",
    "Average test accuracy=0.9767\n",
    "Average test likelihood=-20.4329043034\n",
    "\n",
    "14 componts: used  36.81976127624512  s\n",
    "Average test accuracy=0.9767\n",
    "Average test likelihood=-20.3551120305\n",
    "\n",
    "15 componts: used  34.7089467048645  s\n",
    "Average test accuracy=0.9783\n",
    "Average test likelihood=-20.2039571159\n",
    "\n",
    "16 componts: used  44.527403831481934  s\n",
    "Average test accuracy=0.9772\n",
    "Average test likelihood=-20.2983011337"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PCA and pooling\n",
    "\n",
    "1 componts: used  3.1830551624298096  s\n",
    "Average test accuracy=0.9567\n",
    "Average test likelihood=-36.2042631162\n",
    "\n",
    "2 componts: used  7.420492649078369  s\n",
    "Average test accuracy=0.9602\n",
    "Average test likelihood=-31.7591042082\n",
    "\n",
    "3 componts: used  11.242038249969482  s\n",
    "Average test accuracy=0.9655\n",
    "Average test likelihood=-29.5142338082\n",
    "\n",
    "4 componts: used  13.700795888900757  s\n",
    "Average test accuracy=0.9665\n",
    "Average test likelihood=-28.2874976833\n",
    "\n",
    "5 componts: used  14.583755016326904  s\n",
    "Average test accuracy=0.9702\n",
    "Average test likelihood=-27.5875672\n",
    "\n",
    "6 componts: used  17.52365279197693  s\n",
    "Average test accuracy=0.9712\n",
    "Average test likelihood=-26.8008957843\n",
    "\n",
    "7 componts: used  25.132725715637207  s\n",
    "Average test accuracy=0.9721\n",
    "Average test likelihood=-26.326575347\n",
    "\n",
    "8 componts: used  25.10199236869812  s\n",
    "Average test accuracy=0.9735\n",
    "Average test likelihood=-25.9132286981\n",
    "\n",
    "9 componts: used  32.544289350509644  s\n",
    "Average test accuracy=0.9738\n",
    "Average test likelihood=-25.6263502944\n",
    "\n",
    "10 componts: used  30.238792657852173  s\n",
    "Average test accuracy=0.9749\n",
    "Average test likelihood=-25.3770690498\n",
    "\n",
    "11 componts: used  34.37643098831177  s\n",
    "Average test accuracy=0.974\n",
    "Average test likelihood=-25.2129283934\n",
    "\n",
    "12 componts: used  36.84765672683716  s\n",
    "Average test accuracy=0.9738\n",
    "Average test likelihood=-25.1505724874\n",
    "\n",
    "13 componts: used  28.085733652114868  s\n",
    "Average test accuracy=0.9752\n",
    "Average test likelihood=-25.0308937104\n",
    "\n",
    "14 componts: used  33.18483352661133  s\n",
    "Average test accuracy=0.9734\n",
    "Average test likelihood=-25.0813012886\n",
    "\n",
    "15 componts: used  33.19622778892517  s\n",
    "Average test accuracy=0.9765\n",
    "Average test likelihood=-24.962919031\n",
    "\n",
    "16 componts: used  37.88022804260254  s\n",
    "Average test accuracy=0.9755\n",
    "Average test likelihood=-24.8826691399\n",
    "\n",
    "17 componts: used  38.475733280181885  s\n",
    "Average test accuracy=0.9752\n",
    "Average test likelihood=-25.0300741566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "179px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
