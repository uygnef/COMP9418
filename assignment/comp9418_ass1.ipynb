{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 (Part 2)\n",
    "** COMP9418 - Advanced Topics in Statistical Machine Learning **\n",
    "\n",
    "** Instructor: Edwin V. Bonilla **\n",
    "\n",
    "** Last update: August 23rd at 10:35pm **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "In this practical part of the assignment you will build a class-conditional classifer using Gaussian Mixture Models (GMMs). \n",
    "\n",
    "1. For all the machine-learning related code you have two options: (a) use [scikit-learn](http://scikit-learn.org/stable/) and/or (b) write your own code. In particular, for fitting GMMs or building the classifier, you should refrain from using other packages. \n",
    "2. You can use the same GMM package that we used in the corresponding tutorial on GMMs, i.e. [scikit-learn Gaussian Mixture](http://scikit-learn.org/stable/modules/mixture.html). You should use standard (non-variational) Expectation-Maximisation updates  for parameter estimation. \n",
    "3. Do not delete any of the existing code in this notebook as we will use it to assess the performance of your algorithm.\n",
    "\n",
    "### Main task\n",
    "Your tasks is to build a class-conditional classifier for classifying digits using the MNIST dataset. You are given a file `mnist_train.npz` that contains images of digits (0-9). \n",
    "- The features `xtrain`, which have been normalized to be between [0,1], are 784 dimensional vectors corresponding to 28 * 28 image intensities. \n",
    "- The targets `ytrain` contain the class label of each example using one-hot-encoding. \n",
    "- In total there are 60,000 examples, each with one label from the 10 different classes. \n",
    "- The original dataset can be found at http://yann.lecun.com/exdb/mnist/ and you can read more about this dataset there. However, this dataset has been processed and shuffled so the training and test data in this exercise do not correspond to the original sets. \n",
    "- Note that you are only provided with training data `xtrain`, `ytrain`. In order to learn and test you model, you may consider splitting these data into training, validation and testing.   In particular, if you want to assess the performance of your model in section 2, you must create a test set `mnist_test.npz`. You are not required to submit this test file as we will evaluate the performance of your model using our own test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher\n",
    "Recall that a class-conditional classifier models the joint distribution of features $\\mathbf{x}$ and classes $y$ as $p(\\mathbf{x}, y) = p(y) p(\\mathbf{x} | y)$ and then uses Bayes' rule $p(y | \\mathbf{x}) \\propto  p(y) p(\\mathbf{x} | y)$ to make predictions. In this assignment, you will use a GMM for each of the conditional densities $p(\\mathbf{x} | y)$ and a Categorical distribution for $p(y)$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment\n",
    "Your work will be assessed based on:\n",
    "- [50%] the application of the concepts for doing model selection, which allows you to learn a single model for prediction (Section 1);  \n",
    "- [30%] the code you write for making predicitions in your model (Section 2); and\n",
    "- [20%] the predictive performance of your model (Section 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages \n",
    "Add required libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sklearn as skl\n",
    "\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function below to plot a digit in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(array, dim=28):\n",
    "    \"\"\"\n",
    "    Plot array as an image of dimensions dim * dim\n",
    "    \"\"\"\n",
    "    img = array.reshape(dim,dim, order = \"C\")\n",
    "    pl.imshow(img, cmap=pl.cm.gray)\n",
    "    ax = pl.gca();ax.set_yticks([]);ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you should load your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('mnist_train.npz')\n",
    "\n",
    "# training data\n",
    "xtrain = data['xtrain']\n",
    "ytrain = data['ytrain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here and example of plotting a specific digit and showing its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwIJFwIJFwL9F1rvFqkWhbDJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24cf7eb8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "plot_image(xtrain[idx,:])\n",
    "print(ytrain[idx,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [50%] Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place all the code for training your model using the function `train_model` below. \n",
    "\n",
    "- We should be able to run your notebook (by clicking 'Cell->Run All') without errors. However, you must save the trained model in the file `model.npz`. This file will be loaded to make predictions in section 2 and assess the performance of your model in section 3. Note that, in addition to this notebook file, <span style=\"color:red\"> ** you must provide the file model.npz **</span>.\n",
    "\n",
    "- You should comment your code as much as possible so we understand your reasoning about training, model selection and avoiding overfitting. \n",
    "\n",
    "- You can process the data as you wish, e.g. by applying some additonal transformations, reducing dimensionality, etc. However, all these should be here too. \n",
    "- Wrap all your training using the function `train_model` below. You can call all other custom functions within it.\n",
    "\n",
    "- I strongly discourage you from using a full covariance for each of the components of your Gaussian mixture, as the number of parameters grows quadratically on the dimensionality of the data and you will be unable to fit the file size cap in your submission (besides running into various numerical issues). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2531b53729f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgmm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-2531b53729f7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(xtrain, ytrain)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmixture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianMixture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[1;31m# You can modify this to save other variables, etc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;31m# but make sure the name of the file is 'model.npz.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mprev_lower_bound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_bound_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 self.lower_bound_ = self._compute_lower_bound(\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_prob_resp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_prob_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py\u001b[0m in \u001b[0;36m_estimate_log_prob_resp\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mlogarithm\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresponsibilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mweighted_log_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_weighted_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0mlog_prob_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_log_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py\u001b[0m in \u001b[0;36m_estimate_weighted_log_prob\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mweighted_log_prob\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_log_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\gaussian_mixture.py\u001b[0m in \u001b[0;36m_estimate_log_prob\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_estimate_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         return _estimate_log_gaussian_prob(\n\u001b[0;32m--> 673\u001b[0;31m             X, self.means_, self.precisions_cholesky_, self.covariance_type)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_estimate_log_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\gaussian_mixture.py\u001b[0m in \u001b[0;36m_estimate_log_gaussian_prob\u001b[0;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecisions_chol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_chol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0mlog_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_model(xtrain, ytrain):\n",
    "    \"\"\"\n",
    "    Write your code here.\n",
    "    \"\"\"\n",
    "    from sklearn import mixture\n",
    "    gmm = mixture.GaussianMixture(n_components=10)\n",
    "    gmm.fit(xtrain, y = ytrain)\n",
    "    # You can modify this to save other variables, etc \n",
    "    # but make sure the name of the file is 'model.npz.\n",
    "    np.savez_compressed(\n",
    "        'model.npz',\n",
    "        model=gmm,\n",
    "    )\n",
    "train_model(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [30%] Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will assume that there is a file `mnist_test.npz` from which we will load the test data.  As this file is not given to you, you will need to create one yourself (but not to submit it) to test your code. <span style=\"color:red\">Note that if you do not create this file the cell below will not run</span>. \n",
    "\n",
    "Your task is to fill in the `make_predictions` function below. Note that this function should load your `model.npz` file, which must contain all the data structures necessary for making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a3d13abb5794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;31m# test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xtest'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ytest'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.npz'"
     ]
    }
   ],
   "source": [
    "test = np.load('model.npz')\n",
    "# test data\n",
    "xtest = test['xtest']\n",
    "ytest = test['ytest']\n",
    "idx = 1000\n",
    "plot_image(xtest[idx,:])\n",
    "print (ytest[idx,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(xtest):\n",
    "    \"\"\"\n",
    "    @param xtest: (Ntest,D)-array with test data\n",
    "    @return class_pred: (N,C)-array with predicted classes using one-hot-encoding \n",
    "    @return class_logprob: (N,C)-array with  predicted log probability of the classes   \n",
    "    \"\"\"\n",
    "\n",
    "    # Add your code here: You should load your trained model here \n",
    "    # and write to the corresponding code for making predictions\n",
    "    model = np.load('model.npz');\n",
    "\n",
    "    \n",
    "    return class_pred, class_logprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [20%] Performance \n",
    "You do not need to do anything in this section but you can use it to test the generalisation performance of your code. We will use it the evaluate the performance of your algorithm on a new test test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictive_performance(xdata, ydata, class_pred, class_logprob):\n",
    "    \"\"\"\n",
    "    @param xdata:  (N,D)-array of features \n",
    "    @param ydata:  (N,C)-array of one-hot-encoded true classes\n",
    "    @class_pred: (N,C)-array of one-hot-encoded predicted classes\n",
    "    @class_logprob: (N,C)-array of predicted class log probabilities \n",
    "    \"\"\"\n",
    "    correct = np.zeros(xdata.shape[0])\n",
    "    ltest = np.zeros(xdata.shape[0])\n",
    "    for i, x in enumerate(xdata):\n",
    "        correct[i] = np.all(ydata[i, :] == class_pred[i,:])\n",
    "        ltest[i] = class_logprob[i, np.argmax(ydata[i,:])]\n",
    "    accuracy = correct.mean()\n",
    "    loglike = ltest.mean()\n",
    "    return accuracy, loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_pred, class_logprob = make_predictions(xtest)\n",
    "accuracy, loglike = predictive_performance(xtest, ytest, class_pred, class_logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Average test accuracy=' + str(accuracy)\n",
    "print 'Average test likelihood=' + str(loglike)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "179px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
