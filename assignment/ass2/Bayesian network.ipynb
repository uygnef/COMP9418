{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from edward.models import Categorical, Normal\n",
    "import edward as ed\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import scipy.io as sio   \n",
    "\n",
    "# load data\n",
    "matfn = 'trajectories_xtest.mat'\n",
    "data = sio.loadmat(matfn)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1 1\n",
      "7 7 7\n",
      "16 16 16\n",
      "15 15 15\n",
      "1 1 1\n",
      "13 13 13\n",
      "12 12 12\n",
      "16 16 16\n",
      "11 0 0\n",
      "4 4 4\n",
      "17 17 17\n",
      "14 14 14\n",
      "8 8 8\n",
      "15 15 15\n",
      "3 3 3\n",
      "8 8 8\n",
      "9 9 9\n",
      "13 13 13\n",
      "3 3 3\n",
      "4 4 4\n",
      "11 11 11\n",
      "19 5 19\n",
      "10 10 10\n",
      "5 7 7\n",
      "16 16 16\n",
      "4 4 4\n",
      "19 19 19\n",
      "13 15 15\n",
      "4 4 4\n",
      "11 11 11\n",
      "11 11 11\n",
      "4 4 4\n",
      "3 3 3\n",
      "12 12 12\n",
      "2 2 2\n",
      "5 5 5\n",
      "12 12 12\n",
      "16 16 16\n",
      "14 14 14\n",
      "16 16 16\n",
      "17 17 17\n",
      "7 7 7\n",
      "3 3 3\n",
      "19 19 19\n",
      "11 11 11\n",
      "18 18 18\n",
      "5 5 5\n",
      "7 7 7\n",
      "19 19 19\n",
      "8 8 8\n",
      "13 13 13\n",
      "5 5 5\n",
      "0 0 0\n",
      "3 3 3\n",
      "16 16 16\n",
      "3 3 3\n",
      "4 4 4\n",
      "14 14 14\n",
      "4 4 4\n",
      "13 9 13\n",
      "6 6 6\n",
      "11 10 10\n",
      "9 9 9\n",
      "15 15 15\n",
      "1 1 1\n",
      "14 14 14\n",
      "11 10 10\n",
      "6 6 6\n",
      "12 12 12\n",
      "18 18 18\n",
      "5 5 5\n",
      "14 14 14\n",
      "5 5 5\n",
      "0 0 0\n",
      "9 9 9\n",
      "9 9 9\n",
      "7 7 7\n",
      "19 19 19\n",
      "14 14 14\n",
      "11 11 11\n",
      "6 6 6\n",
      "19 19 19\n",
      "15 15 15\n",
      "13 13 13\n",
      "15 15 15\n",
      "11 0 0\n",
      "4 4 4\n",
      "14 14 14\n",
      "2 2 2\n",
      "16 16 16\n",
      "4 4 4\n",
      "4 4 4\n",
      "5 5 5\n",
      "11 11 11\n",
      "1 1 1\n",
      "18 18 18\n",
      "16 15 15\n",
      "12 12 12\n",
      "4 4 4\n",
      "6 6 6\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file = open('x_prob_lst', 'rb')\n",
    "x_prob_lst = pickle.load(file)\n",
    "xfile = open('y_prob_lst', 'rb')\n",
    "y_prob_lst = pickle.load(xfile)\n",
    "xfile = open('z_prob_lst', 'rb')\n",
    "z_prob_lst = pickle.load(xfile)\n",
    "e = 0\n",
    "\n",
    "result = []\n",
    "for i in range(len(x_prob_lst[0])):\n",
    "    result.append((x_prob_lst[0][i] + y_prob_lst[0][i] + 2 * z_prob_lst[0][i])/4)\n",
    "\n",
    "for i in range(100):\n",
    "    print(np.argmax(x_prob_lst[0][i]), np.argmax(y_prob_lst[0][i]), np.argmax(z_prob_lst[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.70973491e-09   8.35413575e-01   2.48845098e-16   2.70130823e-24\n",
      "   1.43831780e-16   8.05558784e-07   7.17853294e-12   1.93417046e-10\n",
      "   1.60661546e-08   9.27302055e-11   1.14584991e-12   1.64585546e-01\n",
      "   9.10040679e-15   1.87140123e-10   8.36718802e-12   2.99452734e-25\n",
      "   3.08580800e-16   7.34465298e-20   5.91273096e-16   6.41769547e-15]\n",
      "[  3.17546271e-12   3.72269541e-01   8.12807522e-16   8.66758395e-24\n",
      "   1.14396785e-20   3.15795637e-06   4.36557208e-17   6.40218044e-12\n",
      "   1.08984063e-16   1.58939179e-15   3.31862499e-21   6.27727270e-01\n",
      "   1.09981538e-21   2.66133686e-13   1.97243883e-15   8.78283278e-34\n",
      "   7.26179133e-16   2.93779890e-19   1.12810048e-24   1.86600046e-23]\n",
      "[  2.28357617e-08   9.99005139e-01   1.50808724e-17   2.11870369e-24\n",
      "   5.74004318e-16   4.81035194e-08   2.87129816e-11   7.67265973e-10\n",
      "   6.42636309e-08   3.70915937e-10   5.45105216e-15   9.94759728e-04\n",
      "   5.62317251e-20   8.07413557e-14   1.86845128e-17   5.08318552e-31\n",
      "   5.08144065e-16   6.12422106e-24   2.36509238e-15   9.66976783e-24]\n",
      "[  7.44881144e-16   9.85189855e-01   8.37460019e-17   9.47247304e-27\n",
      "   6.55681360e-19   8.08751821e-09   5.53158201e-16   2.33654204e-17\n",
      "   4.93220644e-13   1.65737656e-15   2.28897435e-12   1.48100993e-02\n",
      "   1.82007848e-14   3.74106801e-10   1.67333803e-11   5.98905221e-25\n",
      "   1.91072351e-23   4.76602365e-26   1.70958323e-37   1.28353909e-14]\n"
     ]
    }
   ],
   "source": [
    "i= 0\n",
    "print((x_prob_lst[0][i] + y_prob_lst[0][i] + 2 * z_prob_lst[0][i])/4)\n",
    "print(x_prob_lst[0][i])\n",
    "print(y_prob_lst[0][i])\n",
    "print(z_prob_lst[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "with open('predictions.txt', 'w') as file:\n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            if j == 0.0:\n",
    "                file.write(str(math.log(sys.float_info.min)) + \",\")\n",
    "            else:\n",
    "                file.write(str(math.log(j)) + \",\")\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 16 15 1 13 12 16 0 4 17 14 8 15 3 8 9 13 3 4 11 19 10 7 16 4 19 15 4 11 11 4 3 12 2 5 12 16 14 16 17 7 3 19 11 18 5 7 19 8 13 5 0 3 16 3 4 14 4 13 6 10 9 15 1 14 10 6 12 18 5 14 5 0 9 9 7 19 14 11 6 19 15 13 15 0 4 14 2 16 4 4 5 11 1 18 15 12 4 6 12 4 13 14 2 18 4 8 3 4 0 3 9 8 11 6 14 0 7 8 0 17 2 13 7 12 17 12 1 3 11 5 5 10 14 7 4 10 6 5 11 1 15 7 18 5 16 8 17 17 3 12 6 0 13 19 18 1 19 18 7 8 11 0 10 16 16 13 16 14 11 7 16 17 8 6 4 9 13 3 5 5 15 9 13 11 19 12 7 8 6 5 17 15 4 14 15 11 15 17 4 7 0 1 12 13 10 5 3 18 12 0 3 18 5 10 0 4 11 9 16 4 17 0 12 19 7 19 4 2 16 19 1 10 16 3 8 14 8 8 3 14 0 2 8 7 1 2 1 18 2 17 5 11 1 15 19 1 11 8 1 0 9 6 16 13 0 15 5 7 10 19 5 11 4 8 4 18 19 4 19 9 4 13 19 15 9 9 4 2 15 0 4 18 0 0 1 4 10 1 2 6 9 4 19 2 3 3 19 9 5 2 4 13 13 13 3 17 16 19 12 8 3 9 4 2 0 15 7 6 1 18 10 16 10 9 11 1 16 19 2 12 2 4 4 2 8 17 8 6 13 16 6 7 3 16 4 19 18 5 0 17 9 14 19 8 0 16 19 9 16 9 3 19 14 9 18 13 4 19 0 19 12 19 15 4 6 11 4 7 19 9 2 15 5 0 9 0 1 18 14 18 11 18 2 6 14 16 5 19 11 0 6 7 6 0 6 19 14 9 18 6 8 6 13 13 3 1 5 12 7 14 7 16 8 16 14 15 10 11 15 8 0 10 16 10 2 7 12 8 7 12 8 11 8 19 16 19 16 16 15 7 10 0 14 6 11 6 17 13 7 9 16 6 18 1 8 14 15 10 7 15 18 18 13 15 19 2 12 7 9 11 16 9 11 16 18 4 7 17 8 6 1 15 6 7 2 12 3 1 7 14 16 14 18 5 1 5 0 5 3 10 12 2 4 10 3 7 19 13 6 18 10 15 15 4 15 4 8 12 14 17 16 4 19 9 4 1 7 17 1 17 15 11 1 0 11 11 14 4 2 15 17 5 0 5 3 7 5 4 13 1 1 16 19 16 10 1 2 16 2 4 13 9 16 4 1 9 16 17 2 7 6 3 10 0 6 13 16 0 1 18 3 1 7 1 18 3 0 17 11 4 3 19 15 12 3 9 11 3 10 19 10 9 18 4 19 19 12 14 14 8 19 4 2 13 18 16 1 2 1 15 3 12 15 11 11 4 19 16 4 4 7 12 14 16 14 4 16 11 18 5 17 17 15 3 14 10 2 18 10 5 1 5 16 19 8 7 0 19 13 1 10 19 0 2 7 15 8 18 11 16 15 4 12 15 5 5 8 1 8 9 5 14 0 13 13 7 11 0 13 13 9 14 19 7 16 0 3 10 2 11 4 0 17 6 12 7 19 1 14 11 4 16 4 14 4 12 0 1 4 10 19 3 0 1 10 2 6 8 1 9 12 17 19 1 5 11 17 10 10 11 2 4 1 0 16 5 8 12 18 9 11 16 1 13 17 4 0 7 3 14 4 4 9 11 7 3 12 12 8 18 1 1 12 17 2 3 1 9 13 7 14 3 1 4 19 17 15 3 3 1 2 9 5 7 7 17 16 1 11 8 2 3 4 10 7 16 10 8 0 13 9 18 0 7 8 7 13 19 17 10 2 7 1 17 13 0 3 18 14 14 9 12 3 9 2 14 0 5 15 15 7 1 19 12 2 19 7 14 16 19 19 15 17 9 16 19 15 13 5 11 10 15 7 7 19 3 4 8 10 19 2 3 15 3 18 7 4 18 16 15 0 7 0 10 8 14 6 10 1 7 7 10 11 1 18 14 13 3 4 5 17 15 10 11 4 16 19 19 8 6 16 2 19 3 3 10 8 9 8 2 2 19 13 1 19 18 11 19 17 16 1 16 12 2 5 5 17 17 3 13 8 14 13 12 17 13 8 6 9 10 18 5 2 13 18 9 5 5 16 2 10 12 19 0 7 11 14 14 0 1 13 4 0 18 15 2 15 18 16 0 0 19 0 14 16 18 9 14 12 15 6 1 19 17 4 0 1 5 17 11 14 15 13 6 3 16 18 8 16 9 10 10 13 1 12 5 3 14 10 11 19 2 10 5 10 4 4 9 3 19 7 4 19 14 13 6 5 16 13 12 17 14 3 8 8 16 19 19 4 11 14 0 8 4 14 13 2 17 4 1 2 4 19 0 8 12 15 0 4 9 3 16 19 13 14 8 1 15 9 6 4 2 6 6 1 6 18 13 11 5 3 18 4 4 5 5 12 3 17 18 0 10 18 2 0 4 12 7 11 0 17 14 14 1 4 15 2 5 17 0 3 13 11 10 5 9 12 1 11 0 0 5 1 11 8 0 17 7 11 18 17 9 18 16 3 2 18 6 18 18 16 2 18 19 10 19 2 3 10 17 16 1 7 18 17 19 17 0 6 7 18 11 13 19 4 5 5 1 5 5 2 17 19 6 14 0 7 13 2 18 18 5 16 4 19 16 6 8 0 11 16 1 11 16 5 8 8 6 6 19 1 3 19 8 2 19 1 19 19 19 18 5 19 16 3 5 15 19 0 16 16 15 7 9 6 1 7 16 12 0 17 0 5 10 10 7 0 9 3 6 4 12 1 4 3 14 12 8 3 14 5 18 9 13 9 7 1 15 1 11 14 8 8 12 14 2 4 11 16 15 7 1 3 7 6 13 1 2 7 0 7 5 6 0 12 10 5 16 1 18 7 1 12 12 4 15 10 18 16 11 7 9 5 16 14 16 12 8 3 16 11 10 16 4 0 19 0 18 5 17 10 19 12 11 2 16 11 16 19 18 6 8 18 11 15 1 5 10 6 6 0 4 6 7 4 10 7 5 5 9 3 18 2 16 14 3 6 17 17 4 15 0 2 8 1 2 17 13 15 10 5 10 0 16 7 15 6 11 5 9 9 15 2 17 11 8 8 11 0 19 10 10 8 16 12 13 11 "
     ]
    }
   ],
   "source": [
    "f = open('predictions.txt', 'r')\n",
    "line = f.readline()\n",
    "while line:\n",
    "    a = line\n",
    "    a = a.strip().split(',')[:-1]\n",
    "    c = [float(i) for i in a]\n",
    "    print(np.argmax(c), end=' ')\n",
    "    line = f.readline()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "# make all data be the same size \n",
    "\n",
    "def padding(data):\n",
    "    max_len = max([ i.shape[-1] for i in data['xtrain'][0]])\n",
    "\n",
    "    trans_data = []\n",
    "    for i in data['xtrain'][0]:\n",
    "        i = i.reshape(-1,3)\n",
    "        len_ = i.shape[0]\n",
    "\n",
    "        # padding for shorter data.\n",
    "        if max_len - len_:\n",
    "            trans_data.append(np.vstack(( i, [i[-1]] * (max_len- len_)))) \n",
    "        else:\n",
    "            trans_data.append(i)\n",
    "    return np.array(trans_data)\n",
    "\n",
    "a = padding(data)\n",
    "print(len(a))\n",
    "print(len(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 205, 3)\n",
      "(1, 1429)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2,  8, 17], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "xtrain = padding(data)\n",
    "ytrain = data['ytrain']\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "ytrain[0][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 205, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1429, 205, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = xtrain[1428:] + xtrain[:0]\n",
    "print(a.shape)\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 205, 3)\n"
     ]
    }
   ],
   "source": [
    "# get next minibatch\n",
    "def get_next(i, batch_size):\n",
    "    if i+batch_size < xtrain.shape[0]:\n",
    "        end = i + batch_size\n",
    "        x = x_[i:end]\n",
    "        y = ytrain[0][i:end]\n",
    "    else:\n",
    "        end = xtrain.shape[0] - i + batch_size\n",
    "        x = x_[i:] + x_[:end]\n",
    "        y = ytrain[0][i:] + ytrain[0][:end]\n",
    "    return x, y, i\n",
    "\n",
    "# TODO: use np.hsplit???\n",
    "def sperate_x_y_z(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in data:\n",
    "        temp_x = []\n",
    "        temp_y = []\n",
    "        temp_z = []\n",
    "        for j in i:\n",
    "            temp_x.append(j[0])\n",
    "            temp_y.append(j[1])\n",
    "            temp_z.append(j[2])\n",
    "        x.append(temp_x)\n",
    "        y.append(temp_y)\n",
    "        z.append(temp_z)\n",
    "    return np.array(x), np.array(y), np.array(z)\n",
    "print(xtrain.shape)\n",
    "x_, y_, z_ = sperate_x_y_z(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 8s | Loss: 510.179\n"
     ]
    }
   ],
   "source": [
    "# bayesian netword model\n",
    "N = 100   # number of images in a minibatch.\n",
    "D = max([ i.shape[-1] for i in data['xtrain'][0]])  # number of features.\n",
    "K = 20    # number of classes.\n",
    "\n",
    "# Create a placeholder to hold the data (in minibatches) in a TensorFlow graph.\n",
    "x = tf.placeholder(tf.float32, [None, D])\n",
    "# Normal(0,1) priors for the variables. Note that the syntax assumes TensorFlow 1.1.\n",
    "w = Normal(loc=tf.zeros([D, K]), scale=tf.ones([D, K]))\n",
    "b = Normal(loc=tf.zeros(K), scale=tf.ones(K))\n",
    "# Categorical likelihood for classication.\n",
    "y = Categorical(tf.matmul(x,w)+b)\n",
    "\n",
    "# Contruct the q(w) and q(b). in this case we assume Normal distributions.\n",
    "qw = Normal(loc=tf.Variable(tf.random_normal([D, K])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, K]))))\n",
    "qb = Normal(loc=tf.Variable(tf.random_normal([K])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([K]))))\n",
    "\n",
    "# We use a placeholder for the labels in anticipation of the traning data.\n",
    "y_ph = tf.placeholder(tf.int32, [N])\n",
    "# Define the VI inference technique, ie. minimise the KL divergence between q and p.\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={y:y_ph})\n",
    "\n",
    "# Initialse the infernce variables\n",
    "inference.initialize(n_iter=5000, n_print=100, scale={y: float(xtrain.shape[0]) / N})\n",
    "\n",
    "# We will use an interactive session.\n",
    "sess = tf.InteractiveSession()\n",
    "# Initialise all the vairables in the session.\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Let the training begin. We load the data in minibatches and update the VI infernce using each new batch.\n",
    "i = 0\n",
    "for _ in range(inference.n_iter):\n",
    "    X_batch, Y_batch, i = get_next(i, N)\n",
    "    # TensorFlow method gives the label data in a one hot vetor format. We convert that into a single label.\n",
    "    info_dict = inference.update(feed_dict={x: X_batch, y_ph: Y_batch-1})\n",
    "    inference.print_progress(info_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 "
     ]
    }
   ],
   "source": [
    "X_test, Y_test, ii = get_next(1200, 100)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Generate samples the posterior and store them.\n",
    "n_samples = 100\n",
    "prob_lst = []\n",
    "samples = []\n",
    "w_samples = []\n",
    "b_samples = []\n",
    "for _ in range(n_samples):\n",
    "    print(_, end=\" \")\n",
    "    w_samp = qw.sample()\n",
    "    b_samp = qb.sample()\n",
    "    w_samples.append(w_samp)\n",
    "    b_samples.append(b_samp)\n",
    "    # Also compue the probabiliy of each class for each (w,b) sample.\n",
    "    prob = tf.nn.softmax(tf.matmul( X_test,w_samp ) + b_samp)\n",
    "    prob_lst.append(prob.eval())\n",
    "    sample = tf.concat([tf.reshape(w_samp,[-1]),b_samp],0)\n",
    "    samples.append(sample.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f5573eec7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgDAEv8fF4zfJgYak20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55f9a31198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate samples the posterior and store them.\n",
    "n_samples = 100\n",
    "prob_lst = []\n",
    "samples = []\n",
    "w_samples = []\n",
    "b_samples = []\n",
    "for _ in range(n_samples):\n",
    "    print(_, end=\" \")\n",
    "    w_samp = qw.sample()\n",
    "    b_samp = qb.sample()\n",
    "    w_samples.append(w_samp)\n",
    "    b_samples.append(b_samp)\n",
    "    # Also compue the probabiliy of each class for each (w,b) sample.\n",
    "    prob = tf.nn.softmax(tf.matmul( X_test,w_samp ) + b_samp)\n",
    "    prob_lst.append(prob.eval())\n",
    "    sample = tf.concat([tf.reshape(w_samp,[-1]),b_samp],0)\n",
    "    samples.append(sample.eval())\n",
    "\n",
    "# Compute the accuracy of the model. \n",
    "# For each sample we compute the predicted class and compare with the test labels.\n",
    "# Predicted class is defined as the one which as maximum proability.\n",
    "# We perform this test for each (w,b) in the posterior giving us a set of accuracies\n",
    "# Finally we make a histogram of accuracies for the test data.\n",
    "accy_test = []\n",
    "for prob in prob_lst:\n",
    "    y_trn_prd = np.argmax(prob,axis=1).astype(np.float32)\n",
    "    acc = (y_trn_prd == Y_test-1).mean()*100\n",
    "    accy_test.append(acc)\n",
    "\n",
    "plt.hist(accy_test)\n",
    "plt.title(\"Histogram of prediction accuracies in the test data(only use X vect)\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
