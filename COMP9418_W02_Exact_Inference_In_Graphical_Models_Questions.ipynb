{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Inference in Graphical Models\n",
    "\n",
    "**COMP9418-17s2, W02 Tutorial**\n",
    "\n",
    "- Instructor: Edwin V. Bonilla\n",
    "- School of Computer Science and Engineering, UNSW Sydney\n",
    "- Questions by Daniel Mackinlay and Edwin V. Bonilla\n",
    "- Last Update Tue 8th August at 12:00pm, 2017\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will explore conditional independence graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run these commands:\n",
    "\n",
    "```python\n",
    "pip install pandas matplotlib graphviz\n",
    "```\n",
    "\n",
    "To render the generated DOT source code, you also need to install Graphviz [download page](http://www.graphviz.org/Download.php).\n",
    "\n",
    "You will also need to download the preprocessed `icu_diag.csv` data set\n",
    "(see data file for this tutorial in WebCMS3)\n",
    "and put it in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done all that, we\n",
    "import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from random import random\n",
    "\n",
    "# combinatorics\n",
    "from itertools import product, combinations\n",
    "# ordered dictionaries are useful for keeping ordered sets of varibles\n",
    "from collections import OrderedDict as odict\n",
    "#visualise our graph\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline\n",
    "\n",
    "# easier debugging display\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `pandas`\n",
    "\n",
    "We will be using an external library for the loading tabular data:\n",
    "`pandas.DataFrame` is somewhat similar to `R`. \n",
    "If you which to know more about that, [check out the Pandas intro](http://pandas.pydata.org/pandas-docs/stable/10min.html). \n",
    "We will mostly be ignoring this library, except to load data and display it in nice tables.\n",
    "\n",
    "## Representing graphs\n",
    "\n",
    "We won't be using any special library for representing DAGs in python at this stage in the course.\n",
    "\n",
    "We will model directed graphs in two ways:\n",
    "\n",
    "Firstly, we represent a graph structure as a dictionary of nodes followed by lists of parents, e.g.\n",
    "\n",
    "$A \\rightarrow B \\leftarrow C$\n",
    "\n",
    "will be represented as\n",
    "\n",
    "```\n",
    "{\n",
    "  'A': [],\n",
    "  'B': ['A', 'C'],\n",
    "  'C': [],\n",
    "}\n",
    "```\n",
    "\n",
    "If you'd like to read more about this style of graph, there is\n",
    "[information on the python website](https://www.python.org/doc/essays/graphs/).\n",
    "\n",
    "\n",
    "Later on we will augment this data structure with another one containing conditional probability tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing conditional probability tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will represent the distributions of variables by their joint probability tables - for example, here are 3 random variables, $X$, $Y$, and $Z$, each on $\\{0,1\\}$.\n",
    "\n",
    "  | X | Y | Z | p(X,Y,Z) |\n",
    "  |---|---|---|----------|\n",
    "  | 0 | 0 | 0 | 0 | \n",
    "  | 0 | 0 | 1 | 1/12 | \n",
    "  | 0 | 1 | 0 | 1/12 | \n",
    "  | 0 | 1 | 1 | 1/6 | \n",
    "  | 1 | 0 | 0 | 1/12 | \n",
    "  | 1 | 0 | 1 | 1/6 | \n",
    "  | 1 | 1 | 0 | 1/6 | \n",
    "  | 1 | 1 | 1 | 1/4 | \n",
    "\n",
    "Given these variables and Bayes theorem, it is easy to read off a conditional distribution for, say, $p(Z|X,Y)$, so this is a convenient convention for us to use.\n",
    "\n",
    "\n",
    "  | X | Y | Z | p(Z &#124; X,Y)        |\n",
    "  |---|---|---|---------------------------|\n",
    "  | 0 | 0 | 0 | 0 | \n",
    "  | 0 | 0 | 1 | 1 | \n",
    "  | 0 | 1 | 0 | 1/3 | \n",
    "  | 0 | 1 | 1 | 2/3 | \n",
    "  | 1 | 0 | 0 | 1/3 | \n",
    "  | 1 | 0 | 1 | 2/3 | \n",
    "  | 1 | 1 | 0 | 2/5 | \n",
    "  | 1 | 1 | 1 | 3/5 | \n",
    "\n",
    "The natural question is how we represent a table like this in python;\n",
    "One possible convention is to store these tables in dictionaries, like so, where each combination of conditioning variables indexes the conditional probability table for the conditioned variable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_prob_table = odict([\n",
    "    ((0, 0,), [0.0, 1]),\n",
    "    ((0, 1,), [1/3, 2/3]),\n",
    "    ((1, 0,), [1/3, 2/3]),\n",
    "    ((1, 1,), [2/5, 3/5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persuade yourself that this looks like a typical probability table; since we'll need to estimate a few of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function lets you query the a single conditional probability from this kind of dictionary, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_cond(prob_table, this_val, *parents):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `prob_table`, a dictionary of conditional probabilities,\n",
    "    `this_val` (e.g., 1) the value of the variable we wish to find the probability for\n",
    "    `parents` (e.g. Y=1, Z=1) the parent values that we wish to set.\n",
    "    You must use a consistent order for the parents.\n",
    "    \n",
    "    Returns p(X=this_val|parents(X)=parents)\n",
    "    \"\"\"\n",
    "\n",
    "    prob_array = np.asarray(prob_table[parents])\n",
    "    \n",
    "    if this_val<prob_array.size:\n",
    "        return prob_array[this_val]\n",
    "    elif this_val == prob_array.size:\n",
    "        return 1.0 - prob_array.sum()\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function with the above probability table, we can find $P(Z=1|X=1,Y=1)$ thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Z=1|X=1,Y=1)=0.6\n"
     ]
    }
   ],
   "source": [
    "print('p(Z=1|X=1,Y=1)={}'.format(p_cond(example_prob_table, 1, 1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all the ingredients you need to perform inference over arbitrary probabilistic DAGs.\n",
    "\n",
    "However, to make this worthwhile, we will need to construct a DAG over which to perform inference, and estimate its conditional probabilities.\n",
    "\n",
    "We will estimate these by the method of Maximum Likelihood, from data. But first we need to load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "These data correspond to the problem in the theory part of the tutorial for this week, i.e. the Bayesian network for medical diagnosis in an intensive care unit (ICU). The data are in `csv` format.\n",
    "We can load this in several ways in python, but the most convenient for this purpose \n",
    "is to load it as a `DataFrame` in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('icu_diag.csv') as h:\n",
    "    data = pd.read_csv(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data array, which we call $X$ contains *observations*.\n",
    "Each array is an $N \\times V$ matrix, where each of the $V$ columns\n",
    "contains a variable.\n",
    "Each observation is drawn independently from the probability model.\n",
    "(So each corresponds to one patient arriving at the hospital.)\n",
    "\n",
    "The values in the data are encoded thus:\n",
    "\n",
    "| Variable  |  Value  |  Coding |\n",
    "| :-------: | :-----: | ------: |\n",
    "| H, L, A   |  False  | 0       |\n",
    "| H, L, A   |  True   | 1       |\n",
    "| V, S, T   |  Low    | 0       |\n",
    "| V, S, T   |  High   | 1       |\n",
    "| C, O, B   |  Low    | 0       |\n",
    "| C, O, B   |  Medium | 1       |\n",
    "| C, O, B   |  High   | 2       |\n",
    "\n",
    "We could instead code them using text labels, (`low`, `high`)\n",
    "with a little more work,\n",
    "but that will make some other implementation details more complicated,\n",
    "so we don't do it for now.\n",
    "\n",
    "Let's look at the first few lines of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>O</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  C  B  H  L  O  S  T  V\n",
       "0  0  0  1  1  0  0  1  1  0\n",
       "1  0  1  2  0  0  2  1  1  1\n",
       "2  0  2  2  0  0  2  1  1  1\n",
       "3  0  2  0  0  0  2  1  0  1\n",
       "4  0  1  2  0  0  2  1  1  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the probability tables from the data\n",
    "Much like the categorical estimator from last time, we need to estimator a discrete distribution\n",
    "for each (conditional) probability distribution.\n",
    "\n",
    "To make this a little clearer, we use the following helper function to construct \"Boolean indices\" from tables of data.\n",
    "You can think of this as a `SQL` query using multiple `and` clauses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_equal_this_index(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [False, False, True]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[dict_of_arrays.keys()[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, now, that we already know *a priori* that certain independence relationships hold.\n",
    "In particular, we know that the joint distribution of random variables factorizes according to the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"206pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 206.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 202,-256 202,4 -4,4\"/>\n",
       "<!-- H -->\n",
       "<g id=\"node1\" class=\"node\"><title>H</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">H</text>\n",
       "</g>\n",
       "<!-- V -->\n",
       "<g id=\"node4\" class=\"node\"><title>V</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">V</text>\n",
       "</g>\n",
       "<!-- H&#45;&gt;V -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>H&#45;&gt;V</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-215.697C99,-207.983 99,-198.712 99,-190.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-190.104 99,-180.104 95.5001,-190.104 102.5,-190.104\"/>\n",
       "</g>\n",
       "<!-- S -->\n",
       "<g id=\"node5\" class=\"node\"><title>S</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">S</text>\n",
       "</g>\n",
       "<!-- H&#45;&gt;S -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>H&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.4297,-218.834C74.2501,-208.938 60.4761,-195.546 48.9694,-184.359\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.4055,-181.846 41.7957,-177.385 46.5259,-186.865 51.4055,-181.846\"/>\n",
       "</g>\n",
       "<!-- L -->\n",
       "<g id=\"node2\" class=\"node\"><title>L</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">L</text>\n",
       "</g>\n",
       "<!-- L&#45;&gt;V -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>L&#45;&gt;V</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.5703,-218.834C51.7499,-208.938 65.5239,-195.546 77.0306,-184.359\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.4741,-186.865 84.2043,-177.385 74.5945,-181.846 79.4741,-186.865\"/>\n",
       "</g>\n",
       "<!-- L&#45;&gt;S -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>L&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-215.697C27,-207.983 27,-198.712 27,-190.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5001,-190.104 27,-180.104 23.5001,-190.104 30.5001,-190.104\"/>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node3\" class=\"node\"><title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node6\" class=\"node\"><title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;T -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>A&#45;&gt;T</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171,-143.697C171,-135.983 171,-126.712 171,-118.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.5,-118.104 171,-108.104 167.5,-118.104 174.5,-118.104\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node7\" class=\"node\"><title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- V&#45;&gt;C -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>V&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-143.697C99,-135.983 99,-126.712 99,-118.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-118.104 99,-108.104 95.5001,-118.104 102.5,-118.104\"/>\n",
       "</g>\n",
       "<!-- O -->\n",
       "<g id=\"node8\" class=\"node\"><title>O</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">O</text>\n",
       "</g>\n",
       "<!-- V&#45;&gt;O -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>V&#45;&gt;O</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.4297,-146.834C74.2501,-136.938 60.4761,-123.546 48.9694,-112.359\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.4055,-109.846 41.7957,-105.385 46.5259,-114.865 51.4055,-109.846\"/>\n",
       "</g>\n",
       "<!-- S&#45;&gt;O -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>S&#45;&gt;O</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-143.697C27,-135.983 27,-126.712 27,-118.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5001,-118.104 27,-108.104 23.5001,-118.104 30.5001,-118.104\"/>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node9\" class=\"node\"><title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;B -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>T&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.43,-74.8345C146.25,-64.9376 132.476,-51.5462 120.969,-40.3591\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.405,-37.8461 113.796,-33.3847 118.526,-42.865 123.405,-37.8461\"/>\n",
       "</g>\n",
       "<!-- O&#45;&gt;B -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>O&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.5703,-74.8345C51.7499,-64.9376 65.5239,-51.5462 77.0306,-40.3591\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.4741,-42.865 84.2043,-33.3847 74.5945,-37.8461 79.4741,-42.865\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7ff55ce5a978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use graphviz.Digraph to quickly plot the independence graph.\n",
    "# It's not the topic of this tutorial, but it's handy\n",
    "# https://graphviz.readthedocs.io/en/stable/\n",
    "\n",
    "dot = Digraph(comment='ICU Diagnostic graph')\n",
    "\n",
    "dot.node('H')  # Hypovolemia\n",
    "dot.node('L')  # Left ventricular failure\n",
    "dot.node('A')  # Anaphylaxis\n",
    "dot.node('V')  # Left ventricular endiastolic volume\n",
    "dot.node('S')  # Stroke Volume\n",
    "dot.node('T')  # Total peripheral resistance\n",
    "dot.node('C')  # Central venous pres\n",
    "dot.node('O')  # Cardiac output\n",
    "dot.node('B')  # Blood pressure\n",
    "\n",
    "dot.edges(['HS', 'HV', 'LS', 'LV', 'VO', 'SO', 'VC', 'AT', 'TB', 'OB'])\n",
    "\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have problems with the above code (Digraph), do not worry about it as we use it only to visualize the Bayesian network. You can continue with the tutorial. We will first define a data structure to represent this DAG, \n",
    "using the dictionary representation introduced earlier\n",
    "by setting up some variables to define node parents,\n",
    "and we will define an extra dictionary to record the different possible values each node can take.\n",
    "\n",
    "**Pro tip**: You can experience weird bugs if you are not careful with the order in which you define your variables in their graph. Python `set` and `dict` objects do not maintain orders for their elements. `list` and `tuple` object do maintain order. Since it's convenient to access the dictionary of variables in a consistent order, we use `OrderedDict` (`odict`) objects to maintain the dictionary in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible outcomes, by variable\n",
    "node_outcome_spaces = dict(\n",
    "    H=(0,1),\n",
    "    L=(0,1),\n",
    "    A=(0,1),\n",
    "    V=(0,1),\n",
    "    S=(0,1),\n",
    "    T=(0,1),\n",
    "    C=(0,1,2),\n",
    "    O=(0,1,2),\n",
    "    B=(0,1,2),\n",
    ")\n",
    "# DAG representation\n",
    "# We use an ordered dictionary, `odict`\n",
    "# because it lets us maintain topological ordering, which lets us be lazy later.\n",
    "node_parents = odict()\n",
    "node_parents['H'] = []\n",
    "node_parents['A'] = []\n",
    "node_parents['L'] = []\n",
    "node_parents['V'] = ['H', 'L']\n",
    "node_parents['S'] = ['H', 'L']\n",
    "node_parents['T'] = ['A']\n",
    "node_parents['C'] = ['V']\n",
    "node_parents['O'] = ['V', 'S']\n",
    "node_parents['B'] = ['O', 'T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate parameters by ML, by constructing joint distributions for each node in our graph.\n",
    "This task is similar to the categorical estimation problem from the last tutorial,\n",
    "in that we will take the proportions of empirical counts as estimates of the probabilities of the counted outcomes, i.e.\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x},\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x}\\mid\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N_\\boldsymbol{y}},\n",
    "$$\n",
    "\n",
    "where $N_{\\boldsymbol{x}, \\boldsymbol{y}}$ is the number of observations of that outcome,\n",
    "$$N_{\\boldsymbol{x}, \\boldsymbol{y}}:=\\sum_i\\boldsymbol{X_i}=\\boldsymbol{x}\\cap\\boldsymbol{Y_i}=\\boldsymbol{y},$$ and $N$ is the total number of observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another helper function. This will calculate joint occurrence probability tables.\n",
    "you invoke it like this\n",
    "```\n",
    "prob_table = est_prob_table(data, 'V', (0,1), ['H', 'L'], ((0,1), (0,1)))\n",
    "```\n",
    "to estimate all conditional occurrence probabilities of $V|H,L$, where each variable has state space $\\{0,1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def est_prob_table(data, var_name, var_outcomes, parent_names, parent_outcomes):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for the parens and\n",
    "    `parent_outcomes` a tuple of all possible parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = all_equal_this_index(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            cond_array.append((var_index & parent_index).sum()/parent_index.sum())\n",
    "        prob_table[parent_combination] = np.asarray(cond_array)\n",
    "            \n",
    "    return prob_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Use the above function to calculate probability tables for all 9 variables in our DAG (Bayesian network structure in the theory part of the tutorial). Store them in a dictionary called `cond_tables_ml`.\n",
    "Does this recover the conditional distribution that you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('H', OrderedDict([((), array([ 0.801,  0.199]))])), ('L', OrderedDict([((), array([ 0.95,  0.05]))])), ('A', OrderedDict([((), array([ 0.996,  0.004]))])), ('V', OrderedDict([((0, 0), array([ 0.04479578,  0.95520422])), ((0, 1), array([ 0.,  1.])), ((1, 0), array([ 0.9947644,  0.0052356])), ((1, 1), array([ 1.,  0.]))])), ('S', OrderedDict([((0, 0), array([ 0.03820817,  0.96179183])), ((0, 1), array([ 0.95238095,  0.04761905])), ((1, 0), array([ 0.47643979,  0.52356021])), ((1, 1), array([ 1.,  0.]))])), ('T', OrderedDict([((0,), array([ 0.30722892,  0.69277108])), ((1,), array([ 1.,  0.]))])), ('C', OrderedDict([((0,), array([ 0.93965517,  0.04310345,  0.01724138])), ((1,), array([ 0.01822917,  0.26302083,  0.71875   ]))])), ('O', OrderedDict([((0, 0), array([ 0.97029703,  0.00990099,  0.01980198])), ((0, 1), array([ 0.22137405,  0.76335878,  0.01526718])), ((1, 0), array([ 0.7761194 ,  0.19402985,  0.02985075])), ((1, 1), array([ 0.00285307,  0.0085592 ,  0.98858773]))])), ('B', OrderedDict([((0, 0), array([ 1.,  0.,  0.])), ((0, 1), array([ 0.30081301,  0.61788618,  0.08130081])), ((1, 0), array([ 0.92682927,  0.07317073,  0.        ])), ((1, 1), array([ 0.01265823,  0.49367089,  0.49367089])), ((2, 0), array([ 0.90047393,  0.08056872,  0.01895735])), ((2, 1), array([ 0.00409836,  0.07786885,  0.91803279]))]))])\n"
     ]
    }
   ],
   "source": [
    "def est_helper(data):\n",
    "    prob_table = odict()\n",
    "\n",
    "    for i in var_name:\n",
    "        var_outcomes = node_outcome_spaces[i]\n",
    "        parent_names = node_parents[i]\n",
    "        parent_outcomes = [node_outcome_spaces[j] for j in parent_names]\n",
    "        prob_table[i] = est_prob_table(data, i, var_outcomes, parent_names, parent_outcomes)\n",
    "    return prob_table\n",
    "        \n",
    "cond_tables_ml = est_helper(data)\n",
    "print(cond_tables_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([((0, 0), array([ 1.,  0.,  0.])),\n",
       "             ((0, 1), array([ 0.30081301,  0.61788618,  0.08130081])),\n",
       "             ((1, 0), array([ 0.92682927,  0.07317073,  0.        ])),\n",
       "             ((1, 1), array([ 0.01265823,  0.49367089,  0.49367089])),\n",
       "             ((2, 0), array([ 0.90047393,  0.08056872,  0.01895735])),\n",
       "             ((2, 1), array([ 0.00409836,  0.07786885,  0.91803279]))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_tables_ml['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by naïve summation\n",
    "\n",
    "We are interested in calculating the conditional distributions.\n",
    "For the moment we will attempt to find the conditional distribution\n",
    "$p(L\\mid C=\\text{high})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute $p(L\\mid C=\\text{high})$ by naïve summation.\n",
    "How many arithmetic operations does this require?\n",
    "\n",
    "To do this, we will need to reconstruct each of the joint probabilities from our graph.\n",
    "Remember that we know that we know a factorization for the joint probabilities,\n",
    "specifically,\n",
    "\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "So we can write a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-1c9e7e408b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_outcome_spaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_loop_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-1c9e7e408b35>\u001b[0m in \u001b[0;36mnested_loop_all\u001b[0;34m(dic1, used, number)\u001b[0m\n\u001b[1;32m     21\u001b[0m                        dic['A'])\n\u001b[1;32m     22\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "def p_joint(B,T,O,C,V,S,H,L,A, cond_tables=cond_tables_ml):\n",
    "    p = p_cond(cond_tables['B'], B, O, T)\n",
    "    p *= p_cond(cond_tables['T'], T, A)\n",
    "    p *= p_cond(cond_tables['O'], O, V, S)\n",
    "    p *= p_cond(cond_tables['C'], C, V)\n",
    "    p *= p_cond(cond_tables['S'], S, H, L)\n",
    "    p *= p_cond(cond_tables['V'], V, H, L)\n",
    "    p *= p_cond(cond_tables['H'], H)\n",
    "    p *= p_cond(cond_tables['L'], L)\n",
    "    p *= p_cond(cond_tables['A'], A)\n",
    "    return p\n",
    "\n",
    "# import copy\n",
    "# def nested_loop_all(dic1, used, number):\n",
    "#     dic = copy.deepcopy(dic1)\n",
    "#     dic['C'] = 1\n",
    "#     dic['L'] = 0\n",
    "#     if used >= len(dic) - 3:\n",
    "#         return p_joint(dic['B'], dic['T'], dic['O'], dic['C'], \n",
    "#                        dic['S'], dic['V'], dic['H'], dic['L'],\n",
    "#                        dic['A'])\n",
    "#     temp = 0\n",
    "#     for i in dic:\n",
    "#         if temp < used:\n",
    "#             temp += 1\n",
    "#             continue\n",
    "#         for j in node_outcome_spaces[i]:\n",
    "#             if (i == \"C\" and j != 1) or (i == 'L' and j != 0):\n",
    "#                 return 0\n",
    "#             dic[i] = j\n",
    "#             number += nested_loop_all(dic, used + 1, number)\n",
    "#     return number    \n",
    "# a = copy.deepcopy(node_outcome_spaces)\n",
    "# print(nested_loop_all(a, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "for i in node_outcome_spaces:\n",
    "    for j in node_outcome_spaces[i]:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute $p(L\\mid C=\\text{high})$ by naïve summation and count the number of additions required.\n",
    "Use `p_joint` and `node_outcome_spaces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_names = node_outcome_spaces.keys()\n",
    "all_outcome_combinations = product(*node_outcome_spaces.values())\n",
    "\n",
    "p_l1_and_c2 = 0.0\n",
    "p_c2 = 0.0\n",
    "n_ops = 0\n",
    "\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by variable elimination\n",
    "\n",
    "## Exercise\n",
    "Recall our factorisation of the distribution\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "Use variable elimination to implement an efficient version of the calculation of\n",
    "$p(L\\mid C=\\text{high}),$ and count how many additions of conditional probabilities you require.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling from a Bayesian network\n",
    "Here we are interested in generating samples from our Bayesian network. A very simple method is _ancestral sampling_ ( See for example Barber section 27.2), where one first samples from nodes without parents and then continues down the network sampling from nodes given the samples from their parents. \n",
    "\n",
    "To sample from a Bayesian network with categorical variables, we first define a useful function to simulate from a categorical distribution, given the corresponding probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wchoose(theta):\n",
    "    \"\"\"\n",
    "    sample rv whose value is one of several categories, with probabilites given by theta\n",
    "    (returns *index* of category chosen, e.g. `2`, not `[0,0,1]`.)\n",
    "    \n",
    "    (Providing the probability of the last category is optional, since it is determined by the others.)\n",
    "    \"\"\"\n",
    "    r = random()\n",
    "    cumsum = 0.0\n",
    "    i = 0\n",
    "    for p in theta:\n",
    "        cumsum += p\n",
    "        if cumsum > r:\n",
    "            return i\n",
    "        i += 1\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* Write a program that estimates $p(L\\mid C=2)$ using ancestral sampling to sample from the required distribution.\n",
    "* Use 1000 samples, and compare your estimate with the previous calculations.\n",
    "* Now repeat the sampling procedure with different numbers of samples, and analyze estimates as a function of number of samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional independence\n",
    "Here we numerically estimate conditional independences.\n",
    "\n",
    "Here is useful function for the following question, to marginalise the distribution by brute-force summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cond_tables_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ebcf367d0d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mp_marginalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond_tables_ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mCalculate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mjoint\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mby\u001b[0m \u001b[0mna\u001b[0m\u001b[0;31mï\u001b[0m\u001b[0mvely\u001b[0m \u001b[0msumming\u001b[0m \u001b[0mover\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFor\u001b[0m \u001b[0mlarge\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msimply\u001b[0m \u001b[0mtoo\u001b[0m \u001b[0minefficient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mOK\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cond_tables_ml' is not defined"
     ]
    }
   ],
   "source": [
    "def p_marginalize(cond_tables=cond_tables_ml, **evidence):\n",
    "    \"\"\"\n",
    "    Calculate a joint probability by naïvely summing over margins.\n",
    "    For large graphs this is simply too inefficient, but it's OK for us.\n",
    "    \n",
    "    >>> p_marginalize(H=0, L=0) + p_marginalize(H=0, L=1) + \\\n",
    "        p_marginalize(H=1, L=0) + p_marginalize(H=1, L=1)\n",
    "    1.0\n",
    "    >>> p_marginalize(H=0, C=0) + p_marginalize(H=0, C=1) + \\\n",
    "        p_marginalize(H=0, C=2) + p_marginalize(H=1, C=0) + \\\n",
    "        p_marginalize(H=1, C=1) + p_marginalize(H=1, C=2)\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    nuisance_vars = list(node_outcome_spaces.keys())\n",
    "    \n",
    "    for node in evidence.keys():\n",
    "        nuisance_vars.pop(nuisance_vars.index(node))\n",
    "    \n",
    "    marginal = 0.0\n",
    "    for outcomes in product(*[\n",
    "            node_outcome_spaces[node] for node in nuisance_vars\n",
    "        ]):\n",
    "        var_values = dict(zip(nuisance_vars, outcomes))\n",
    "        var_values.update(evidence)\n",
    "        marginal += p_joint(**var_values)\n",
    "    return marginal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Show or refute  the conditional independences in the theory tutorial numerically. i.e. \n",
    "determine whether\n",
    "\n",
    "1. $H \\indep L$\n",
    "2. $H \\indep A$\n",
    "3. $C \\indep L$\n",
    "4. $C \\indep L\\mid B$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
