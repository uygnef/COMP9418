{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Inference in Graphical Models\n",
    "\n",
    "**COMP9418-17s2, W02 Tutorial**\n",
    "\n",
    "- Instructor: Edwin V. Bonilla\n",
    "- School of Computer Science and Engineering, UNSW Sydney\n",
    "- Questions by Daniel Mackinlay and Edwin V. Bonilla\n",
    "- Last Update Tue 8th August at 12:00pm, 2017\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will explore conditional independence graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run these commands:\n",
    "\n",
    "```python\n",
    "pip install pandas matplotlib graphviz\n",
    "```\n",
    "\n",
    "To render the generated DOT source code, you also need to install Graphviz [download page](http://www.graphviz.org/Download.php).\n",
    "\n",
    "You will also need to download the preprocessed `icu_diag.csv` data set\n",
    "(see data file for this tutorial in WebCMS3)\n",
    "and put it in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done all that, we\n",
    "import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from random import random\n",
    "\n",
    "# combinatorics\n",
    "from itertools import product, combinations\n",
    "# ordered dictionaries are useful for keeping ordered sets of varibles\n",
    "from collections import OrderedDict as odict\n",
    "#visualise our graph\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline\n",
    "\n",
    "# easier debugging display\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `pandas`\n",
    "\n",
    "We will be using an external library for the loading tabular data:\n",
    "`pandas.DataFrame` is somewhat similar to `R`. \n",
    "If you which to know more about that, [check out the Pandas intro](http://pandas.pydata.org/pandas-docs/stable/10min.html). \n",
    "We will mostly be ignoring this library, except to load data and display it in nice tables.\n",
    "\n",
    "## Representing graphs\n",
    "\n",
    "We won't be using any special library for representing DAGs in python at this stage in the course.\n",
    "\n",
    "We will model directed graphs in two ways:\n",
    "\n",
    "Firstly, we represent a graph structure as a dictionary of nodes followed by lists of parents, e.g.\n",
    "\n",
    "$A \\rightarrow B \\leftarrow C$\n",
    "\n",
    "will be represented as\n",
    "\n",
    "```\n",
    "{\n",
    "  'A': [],\n",
    "  'B': ['A', 'C'],\n",
    "  'C': [],\n",
    "}\n",
    "```\n",
    "\n",
    "If you'd like to read more about this style of graph, there is\n",
    "[information on the python website](https://www.python.org/doc/essays/graphs/).\n",
    "\n",
    "\n",
    "Later on we will augment this data structure with another one containing conditional probability tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing conditional probability tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will represent the distributions of variables by their joint probability tables - for example, here are 3 random variables, $X$, $Y$, and $Z$, each on $\\{0,1\\}$.\n",
    "\n",
    "  | X | Y | Z | p(X,Y,Z) |\n",
    "  |---|---|---|----------|\n",
    "  | 0 | 0 | 0 | 0 | \n",
    "  | 0 | 0 | 1 | 1/12 | \n",
    "  | 0 | 1 | 0 | 1/12 | \n",
    "  | 0 | 1 | 1 | 1/6 | \n",
    "  | 1 | 0 | 0 | 1/12 | \n",
    "  | 1 | 0 | 1 | 1/6 | \n",
    "  | 1 | 1 | 0 | 1/6 | \n",
    "  | 1 | 1 | 1 | 1/4 | \n",
    "\n",
    "Given these variables and Bayes theorem, it is easy to read off a conditional distribution for, say, $p(Z|X,Y)$, so this is a convenient convention for us to use.\n",
    "\n",
    "\n",
    "  | X | Y | Z | p(Z &#124; X,Y)        |\n",
    "  |---|---|---|---------------------------|\n",
    "  | 0 | 0 | 0 | 0 | \n",
    "  | 0 | 0 | 1 | 1 | \n",
    "  | 0 | 1 | 0 | 1/3 | \n",
    "  | 0 | 1 | 1 | 2/3 | \n",
    "  | 1 | 0 | 0 | 1/3 | \n",
    "  | 1 | 0 | 1 | 2/3 | \n",
    "  | 1 | 1 | 0 | 2/5 | \n",
    "  | 1 | 1 | 1 | 3/5 | \n",
    "\n",
    "The natural question is how we represent a table like this in python;\n",
    "One possible convention is to store these tables in dictionaries, like so, where each combination of conditioning variables indexes the conditional probability table for the conditioned variable,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_prob_table = odict([\n",
    "    ((0, 0,), [0.0, 1]),\n",
    "    ((0, 1,), [1/3, 2/3]),\n",
    "    ((1, 0,), [1/3, 2/3]),\n",
    "    ((1, 1,), [2/5, 3/5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persuade yourself that this looks like a typical probability table; since we'll need to estimate a few of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function lets you query the a single conditional probability from this kind of dictionary, which is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_cond(prob_table, this_val, *parents):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `prob_table`, a dictionary of conditional probabilities,\n",
    "    `this_val` (e.g., 1) the value of the variable we wish to find the probability for\n",
    "    `parents` (e.g. Y=1, Z=1) the parent values that we wish to set.\n",
    "    You must use a consistent order for the parents.\n",
    "    \n",
    "    Returns p(X=this_val|parents(X)=parents)\n",
    "    \"\"\"\n",
    "\n",
    "    prob_array = np.asarray(prob_table[parents])\n",
    "    \n",
    "    if this_val<prob_array.size:\n",
    "        return prob_array[this_val]\n",
    "    elif this_val == prob_array.size:\n",
    "        return 1.0 - prob_array.sum()\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function with the above probability table, we can find $P(Z=1|X=1,Y=1)$ thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Z=1|X=1,Y=1)=0.6\n"
     ]
    }
   ],
   "source": [
    "print('p(Z=1|X=1,Y=1)={}'.format(p_cond(example_prob_table, 1, 1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have all the ingredients you need to perform inference over arbitrary probabilistic DAGs.\n",
    "\n",
    "However, to make this worthwhile, we will need to construct a DAG over which to perform inference, and estimate its conditional probabilities.\n",
    "\n",
    "We will estimate these by the method of Maximum Likelihood, from data. But first we need to load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "These data correspond to the problem in the theory part of the tutorial for this week, i.e. the Bayesian network for medical diagnosis in an intensive care unit (ICU). The data are in `csv` format.\n",
    "We can load this in several ways in python, but the most convenient for this purpose \n",
    "is to load it as a `DataFrame` in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('icu_diag.csv') as h:\n",
    "    data = pd.read_csv(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data array, which we call $X$ contains *observations*.\n",
    "Each array is an $N \\times V$ matrix, where each of the $V$ columns\n",
    "contains a variable.\n",
    "Each observation is drawn independently from the probability model.\n",
    "(So each corresponds to one patient arriving at the hospital.)\n",
    "\n",
    "The values in the data are encoded thus:\n",
    "\n",
    "| Variable  |  Value  |  Coding |\n",
    "| :-------: | :-----: | ------: |\n",
    "| H, L, A   |  False  | 0       |\n",
    "| H, L, A   |  True   | 1       |\n",
    "| V, S, T   |  Low    | 0       |\n",
    "| V, S, T   |  High   | 1       |\n",
    "| C, O, B   |  Low    | 0       |\n",
    "| C, O, B   |  Medium | 1       |\n",
    "| C, O, B   |  High   | 2       |\n",
    "\n",
    "We could instead code them using text labels, (`low`, `high`)\n",
    "with a little more work,\n",
    "but that will make some other implementation details more complicated,\n",
    "so we don't do it for now.\n",
    "\n",
    "Let's look at the first few lines of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>O</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  C  B  H  L  O  S  T  V\n",
       "0  0  0  1  1  0  0  1  1  0\n",
       "1  0  1  2  0  0  2  1  1  1\n",
       "2  0  2  2  0  0  2  1  1  1\n",
       "3  0  2  0  0  0  2  1  0  1\n",
       "4  0  1  2  0  0  2  1  1  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the probability tables from the data\n",
    "Much like the categorical estimator from last time, we need to estimator a discrete distribution\n",
    "for each (conditional) probability distribution.\n",
    "\n",
    "To make this a little clearer, we use the following helper function to construct \"Boolean indices\" from tables of data.\n",
    "You can think of this as a `SQL` query using multiple `and` clauses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_equal_this_index(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [False, False, True]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[dict_of_arrays.keys()[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, now, that we already know *a priori* that certain independence relationships hold.\n",
    "In particular, we know that the joint distribution of random variables factorizes according to the following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, quiet)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             startupinfo=STARTUPINFO)\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    706\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[1;32m    989\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                                          startupinfo)\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Yu\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, quiet)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x13800a98668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use graphviz.Digraph to quickly plot the independence graph.\n",
    "# It's not the topic of this tutorial, but it's handy\n",
    "# https://graphviz.readthedocs.io/en/stable/\n",
    "\n",
    "dot = Digraph(comment='ICU Diagnostic graph')\n",
    "\n",
    "dot.node('H')  # Hypovolemia\n",
    "dot.node('L')  # Left ventricular failure\n",
    "dot.node('A')  # Anaphylaxis\n",
    "dot.node('V')  # Left ventricular endiastolic volume\n",
    "dot.node('S')  # Stroke Volume\n",
    "dot.node('T')  # Total peripheral resistance\n",
    "dot.node('C')  # Central venous pres\n",
    "dot.node('O')  # Cardiac output\n",
    "dot.node('B')  # Blood pressure\n",
    "\n",
    "dot.edges(['HS', 'HV', 'LS', 'LV', 'VO', 'SO', 'VC', 'AT', 'TB', 'OB'])\n",
    "\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have problems with the above code (Digraph), do not worry about it as we use it only to visualize the Bayesian network. You can continue with the tutorial. We will first define a data structure to represent this DAG, \n",
    "using the dictionary representation introduced earlier\n",
    "by setting up some variables to define node parents,\n",
    "and we will define an extra dictionary to record the different possible values each node can take.\n",
    "\n",
    "**Pro tip**: You can experience weird bugs if you are not careful with the order in which you define your variables in their graph. Python `set` and `dict` objects do not maintain orders for their elements. `list` and `tuple` object do maintain order. Since it's convenient to access the dictionary of variables in a consistent order, we use `OrderedDict` (`odict`) objects to maintain the dictionary in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible outcomes, by variable\n",
    "node_outcome_spaces = dict(\n",
    "    H=(0,1),\n",
    "    L=(0,1),\n",
    "    A=(0,1),\n",
    "    V=(0,1),\n",
    "    S=(0,1),\n",
    "    T=(0,1),\n",
    "    C=(0,1,2),\n",
    "    O=(0,1,2),\n",
    "    B=(0,1,2),\n",
    ")\n",
    "# DAG representation\n",
    "# We use an ordered dictionary, `odict`\n",
    "# because it lets us maintain topological ordering, which lets us be lazy later.\n",
    "node_parents = odict()\n",
    "node_parents['H'] = []\n",
    "node_parents['A'] = []\n",
    "node_parents['L'] = []\n",
    "node_parents['V'] = ['H', 'L']\n",
    "node_parents['S'] = ['H', 'L']\n",
    "node_parents['T'] = ['A']\n",
    "node_parents['C'] = ['V']\n",
    "node_parents['O'] = ['V', 'S']\n",
    "node_parents['B'] = ['O', 'T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate parameters by ML, by constructing joint distributions for each node in our graph.\n",
    "This task is similar to the categorical estimation problem from the last tutorial,\n",
    "in that we will take the proportions of empirical counts as estimates of the probabilities of the counted outcomes, i.e.\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x},\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x}\\mid\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N_\\boldsymbol{y}},\n",
    "$$\n",
    "\n",
    "where $N_{\\boldsymbol{x}, \\boldsymbol{y}}$ is the number of observations of that outcome,\n",
    "$$N_{\\boldsymbol{x}, \\boldsymbol{y}}:=\\sum_i\\boldsymbol{X_i}=\\boldsymbol{x}\\cap\\boldsymbol{Y_i}=\\boldsymbol{y},$$ and $N$ is the total number of observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another helper function. This will calculate joint occurrence probability tables.\n",
    "you invoke it like this\n",
    "```\n",
    "prob_table = est_prob_table(data, 'V', (0,1), ['H', 'L'], ((0,1), (0,1)))\n",
    "```\n",
    "to estimate all conditional occurrence probabilities of $V|H,L$, where each variable has state space $\\{0,1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def est_prob_table(data, var_name, var_outcomes, parent_names, parent_outcomes):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for hte parens and\n",
    "    `parent_outcomes` a tuple of all possuble parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = all_equal_this_index(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            cond_array.append((var_index & parent_index).sum()/parent_index.sum())\n",
    "        prob_table[parent_combination] = np.asarray(cond_array)\n",
    "            \n",
    "    return prob_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Use the above function to calculate probability tables for all 9 variables in our DAG (Bayesian network structure in the theory part of the tutorial). Store them in a dictionary called `cond_tables_ml`.\n",
    "Does this recover the conditional distribution that you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by naïve summation\n",
    "\n",
    "We are interested in calculating the conditional distributions.\n",
    "For the moment we will attempt to find the conditional distribution\n",
    "$p(L\\mid C=\\text{high})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute $p(L\\mid C=\\text{high})$ by naïve summation.\n",
    "How many arithmetic operations does this require?\n",
    "\n",
    "To do this, we will need to reconstruct each of the joint probabilities from our graph.\n",
    "Remember that we know that we know a factorization for the joint probabilities,\n",
    "specifically,\n",
    "\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "So we can write a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cond_tables_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b0948a03802c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mp_joint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond_tables_ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mp_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mp_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mp_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cond_tables_ml' is not defined"
     ]
    }
   ],
   "source": [
    "def p_joint(B,T,O,C,V,S,H,L,A, cond_tables=cond_tables_ml):\n",
    "    p = p_cond(cond_tables['B'], B, O, T)\n",
    "    p *= p_cond(cond_tables['T'], T, A)\n",
    "    p *= p_cond(cond_tables['O'], O, V, S)\n",
    "    p *= p_cond(cond_tables['C'], C, V)\n",
    "    p *= p_cond(cond_tables['S'], S, H, L)\n",
    "    p *= p_cond(cond_tables['V'], V, H, L)\n",
    "    p *= p_cond(cond_tables['H'], H)\n",
    "    p *= p_cond(cond_tables['L'], L)\n",
    "    p *= p_cond(cond_tables['A'], A)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute $p(L\\mid C=\\text{high})$ by naïve summation and count the number of additions required.\n",
    "Use `p_joint` and `node_outcome_spaces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_names = node_outcome_spaces.keys()\n",
    "all_outcome_combinations = product(*node_outcome_spaces.values())\n",
    "\n",
    "p_l1_and_c2 = 0.0\n",
    "p_c2 = 0.0\n",
    "n_ops = 0\n",
    "\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by variable elimination\n",
    "\n",
    "## Exercise\n",
    "Recall our factorisation of the distribution\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "Use variable elimination to implement an efficient version of the calculation of\n",
    "$p(L\\mid C=\\text{high}),$ and count how many additions of conditional probabilities you require.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling from a Bayesian network\n",
    "Here we are interested in generating samples from our Bayesian network. A very simple method is _ancestral sampling_ ( See for example Barber section 27.2), where one first samples from nodes without parents and then continues down the network sampling from nodes given the samples from their parents. \n",
    "\n",
    "To sample from a Bayesian network with categorical variables, we first define a useful function to simulate from a categorical distribution, given the corresponding probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wchoose(theta):\n",
    "    \"\"\"\n",
    "    sample rv whose value is one of several categories, with probabilites given by theta\n",
    "    (returns *index* of category chosen, e.g. `2`, not `[0,0,1]`.)\n",
    "    \n",
    "    (Providing the probability of the last category is optional, since it is determined by the others.)\n",
    "    \"\"\"\n",
    "    r = random()\n",
    "    cumsum = 0.0\n",
    "    i = 0\n",
    "    for p in theta:\n",
    "        cumsum += p\n",
    "        if cumsum > r:\n",
    "            return i\n",
    "        i += 1\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* Write a program that estimates $p(L\\mid C=2)$ using ancestral sampling to sample from the required distribution.\n",
    "* Use 1000 samples, and compare your estimate with the previous calculations.\n",
    "* Now repeat the sampling procedure with different numbers of samples, and analyze estimates as a function of number of samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional independence\n",
    "Here we numerically estimate conditional independences.\n",
    "\n",
    "Here is useful function for the following question, to marginalise the distribution by brute-force summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cond_tables_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ebcf367d0d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mp_marginalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond_tables_ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mCalculate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mjoint\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mby\u001b[0m \u001b[0mna\u001b[0m\u001b[0;31mï\u001b[0m\u001b[0mvely\u001b[0m \u001b[0msumming\u001b[0m \u001b[0mover\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFor\u001b[0m \u001b[0mlarge\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msimply\u001b[0m \u001b[0mtoo\u001b[0m \u001b[0minefficient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mOK\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cond_tables_ml' is not defined"
     ]
    }
   ],
   "source": [
    "def p_marginalize(cond_tables=cond_tables_ml, **evidence):\n",
    "    \"\"\"\n",
    "    Calculate a joint probability by naïvely summing over margins.\n",
    "    For large graphs this is simply too inefficient, but it's OK for us.\n",
    "    \n",
    "    >>> p_marginalize(H=0, L=0) + p_marginalize(H=0, L=1) + \\\n",
    "        p_marginalize(H=1, L=0) + p_marginalize(H=1, L=1)\n",
    "    1.0\n",
    "    >>> p_marginalize(H=0, C=0) + p_marginalize(H=0, C=1) + \\\n",
    "        p_marginalize(H=0, C=2) + p_marginalize(H=1, C=0) + \\\n",
    "        p_marginalize(H=1, C=1) + p_marginalize(H=1, C=2)\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    nuisance_vars = list(node_outcome_spaces.keys())\n",
    "    \n",
    "    for node in evidence.keys():\n",
    "        nuisance_vars.pop(nuisance_vars.index(node))\n",
    "    \n",
    "    marginal = 0.0\n",
    "    for outcomes in product(*[\n",
    "            node_outcome_spaces[node] for node in nuisance_vars\n",
    "        ]):\n",
    "        var_values = dict(zip(nuisance_vars, outcomes))\n",
    "        var_values.update(evidence)\n",
    "        marginal += p_joint(**var_values)\n",
    "    return marginal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "- Show or refute  the conditional independences in the theory tutorial numerically. i.e. \n",
    "determine whether\n",
    "\n",
    "1. $H \\indep L$\n",
    "2. $H \\indep A$\n",
    "3. $C \\indep L$\n",
    "4. $C \\indep L\\mid B$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
